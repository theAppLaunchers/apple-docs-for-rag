![](https://docs-assets.developer.apple.com/published/4d08bfc19f2c5d1ca49f3c65c77d8aeb/sample-code-library.svg)

# Sample Code Library

Enhance and expand your knowledge of Apple technologies by exploring the full library of sample code projects.

## [Featured at WWDC25](/documentation/samplecode/#Featured-at-WWDC25)

Explore samples that highlight new APIs featured at this year’s conference.

[

![An image with a background of Mount Fuji, and in the foreground screenshots of the landmark detail view for Mount Fuji in the Landmarks app, in an iPad and iPhone.](https://docs-assets.developer.apple.com/published/54d1e5049c272381ddeb6c5d7b04fd25/Landmarks-Building-an-app-with-Liquid-Glass-PageImage-card%402x.png)

Landmarks: Building an app with Liquid Glass

Enhance your app experience with system-provided and custom Liquid Glass.

View sample code

](/documentation/SwiftUI/Landmarks-Building-an-app-with-Liquid-Glass)

[

![](https://docs-assets.developer.apple.com/published/17c1ca7b418385393bd52f0d6ed75730/storekit-workflows-PageImage-card%402x.png)

Understanding StoreKit workflows

Implement an in-app store with several product types, using StoreKit views.

View sample code

](/documentation/StoreKit/understanding-storekit-workflows)

[

![](https://docs-assets.developer.apple.com/published/0d46a37cd4649de679c0e54d0d99cc85/Canyon-Crosser-PageImage-card.png)

Canyon Crosser: Building a volumetric hike-planning app

](/documentation/visionOS/canyon-crosser-building-a-volumetric-hike-planning-app)

[

![](https://docs-assets.developer.apple.com/published/82f8c7674c19f24265584000b0786e9e/petite-asteroids-PageImage-card%402x.png)

Petite Asteroids: Building a volumetric visionOS game

](/documentation/visionOS/petite-asteroids-building-a-volumetric-visionos-game)

[

![](https://docs-assets.developer.apple.com/published/ef2933ee12f46a0829f45e5401748a9d/TabletopKit-mini-game-PageImage-card.png)

Synchronizing group gameplay with TabletopKit

](/documentation/TabletopKit/synchronizing-group-gameplay-with-tabletopkit)

[

![](https://docs-assets.developer.apple.com/published/29399e54b8f238bef3b51af88ed97253/adding-intelligent-app-features-with-generative-models-PageImage-card%402x.png)

Adding intelligent app features with generative models

](/documentation/FoundationModels/adding-intelligent-app-features-with-generative-models)

[

![](https://docs-assets.developer.apple.com/published/80958814f82155ed04715a1ea3e85304/building-rich-swiftUI-text-experiences-PageImage-card%402x.png)

Building rich SwiftUI text experiences

](/documentation/SwiftUI/building-rich-swiftui-text-experiences)

[

![](https://docs-assets.developer.apple.com/published/a4ce835fc26ab63e78e955e95c8cff44/tracking-accessories-in-volumetric-windows-PageImage-card%402x.png)

Tracking accessories in volumetric windows

](/documentation/ARKit/tracking-accessories-in-volumetric-windows)

## [Topics](/documentation/samplecode/#topics)

### [WWDC25](/documentation/samplecode/#WWDC25)

[

Adding intelligent app features with generative models](/documentation/FoundationModels/adding-intelligent-app-features-with-generative-models)

Build robust apps with guided generation and tool calling by adopting the Foundation Models framework.

Beta

[

Adopting App Intents to support system experiences](/documentation/AppIntents/adopting-app-intents-to-support-system-experiences)

Create app intents and entities to incorporate system experiences such as Spotlight, visual intelligence, and Shortcuts.

Beta

[

Adopting SwiftData for a Core Data app](/documentation/CoreData/adopting-swiftdata-for-a-core-data-app)

Persist data in your app intuitively with the Swift native persistence framework.

[

Authoring Apple Immersive Video](/documentation/ImmersiveMediaSupport/authoring-apple-immersive-video)

Prepare and package immersive video content for delivery.

Beta

[

AVCam: Building a camera app](/documentation/AVFoundation/avcam-building-a-camera-app)

Capture photos and record video using the front and rear iPhone and iPad cameras.

Beta

[

Bringing advanced speech-to-text capabilities to your app](/documentation/Speech/bringing-advanced-speech-to-text-capabilities-to-your-app)

Learn how to incorporate live speech-to-text transcription into your app with SpeechAnalyzer.

Beta

[

Building a workout app for iPhone and iPad](/documentation/HealthKit/building-a-workout-app-for-iphone-and-ipad)

Start a workout in iOS, control it from the Lock Screen with App Intents, and present the workout status with Live Activities.

[

Building peer-to-peer apps](/documentation/WiFiAware/Building-peer-to-peer-apps)

Communicate with nearby devices over a secure, high-throughput, low-latency connection by using Wi-Fi Aware.

[

Building rich SwiftUI text experiences](/documentation/SwiftUI/building-rich-swiftui-text-experiences)

Build an editor for formatted text using SwiftUI text editor views and attributed strings.

Beta

[

Canyon Crosser: Building a volumetric hike-planning app](/documentation/visionOS/canyon-crosser-building-a-volumetric-hike-planning-app)

Create a hike planning app using SwiftUI and RealityKit.

Beta

[

Capturing cinematic video](/documentation/AVFoundation/capturing-cinematic-video)

Capture video with an adjustable depth of field and focus points.

Beta

[

Capturing Spatial Audio in your iOS app](/documentation/AVFoundation/capturing-spatial-audio-in-your-ios-app)

Enhance your app’s audio recording capabilities by supporting Spatial Audio capture.

Beta

[

Code-along: Elevating an app with Swift concurrency](/documentation/Swift/code-along-elevating-an-app-with-swift-concurrency)

Code along with the WWDC presenter to elevate a SwiftUI app with Swift concurrency.

[

Converting projected video to Apple Projected Media Profile](/documentation/AVFoundation/converting-projected-video-to-apple-projected-media-profile)

Convert content with equirectangular or half-equirectangular projection to APMP.

Beta

[

Creating a seamless multiview playback experience](/documentation/AVFoundation/creating-a-seamless-multiview-playback-experience)

Build advanced multiview playback experiences with the AVFoundation and AVRouting frameworks.

Beta

[

Editing Spatial Audio with an audio mix](/documentation/Cinematic/editing-spatial-audio-with-an-audio-mix)

Add Spatial Audio editing capabilities with the Audio Mix API in the Cinematic framework.

Beta

[

Enhancing your app with machine learning-based video effects](/documentation/VideoToolbox/enhancing-your-app-with-machine-learning-based-video-effects)

Add powerful effects to your videos using the VideoToolbox VTFrameProcessor API.

[

Enhancing your custom text engine with Writing Tools](/documentation/AppKit/enhancing-your-custom-text-engine-with-writing-tools)

Add Writing Tools support to your custom text engine to enhance the text editing experience.

[

Filtering traffic by URL](/documentation/NetworkExtension/filtering-traffic-by-url)

Perform fast and robust filtering of full URLs by managing URL filtering configurations.

[

Generate dynamic game content with guided generation and tools](/documentation/FoundationModels/generate-dynamic-game-content-with-guided-generation-and-tools)

Make gameplay more lively with AI generated dialog and encounters personalized to the player.

Beta

[

Implementing a background delivery extension](/documentation/FinanceKit/implementing-a-background-delivery-extension)

Receive up-to-date financial data in your app and its extensions by adding a background delivery extension.

[

Implementing a store in your app using the StoreKit API](/documentation/StoreKit/implementing-a-store-in-your-app-using-the-storekit-api)

Offer In-App Purchases and manage entitlements using signed transactions and status information.

[

Landmarks: Applying a background extension effect](/documentation/SwiftUI/Landmarks-Applying-a-background-extension-effect)

Configure an image to blur and extend under a sidebar or inspector panel.

Beta

[

Landmarks: Building an app with Liquid Glass](/documentation/SwiftUI/Landmarks-Building-an-app-with-Liquid-Glass)

Enhance your app experience with system-provided and custom Liquid Glass.

Beta

[

Landmarks: Displaying custom activity badges](/documentation/SwiftUI/Landmarks-Displaying-custom-activity-badges)

Provide people with a way to mark their adventures by displaying animated custom activity badges.

Beta

[

Landmarks: Extending horizontal scrolling under a sidebar or inspector](/documentation/SwiftUI/Landmarks-Extending-horizontal-scrolling-under-a-sidebar-or-inspector)

Improve your horizontal scrollbar’s appearance by extending it under a sidebar or inspector.

Beta

[

Landmarks: Refining the system provided Liquid Glass effect in toolbars](/documentation/SwiftUI/Landmarks-Refining-the-system-provided-glass-effect-in-toolbars)

Organize toolbars into related groupings to improve their appearance and utility.

Beta

[

Language Introspector](/documentation/Foundation/language-introspector)

Converts data into human-readable text using formatters and locales.

[

Localizing Landmarks](/documentation/Xcode/localizing-landmarks)

Add localizations to the Landmarks sample code project.

Beta

[

Logging symptoms associated with a medication](/documentation/HealthKit/logging-symptoms-associated-with-a-medication)

Fetch medications and dose events from the HealthKit store, and create symptom samples to associate with them.

[

Managing location-based reminders](/documentation/EventKit/managing-location-based-reminders)

Access reminders set up with geofence-enabled alarms on a person’s calendars.

[

Optimizing home electricity usage](/documentation/EnergyKit/optimizing-home-electricity-usage)

Shift electric vehicle charging schedules to times when the grid is cleaner and potentially less expensive.

[

Performing fast account creation with passkeys](/documentation/AuthenticationServices/performing-fast-account-creation-with-passkeys)

Allow people to quickly create an account with passkeys and associated domains.

[

Petite Asteroids: Building a volumetric visionOS game](/documentation/visionOS/petite-asteroids-building-a-volumetric-visionos-game)

Use the latest RealityKit APIs to create a beautiful video game for visionOS.

Beta

[

Playing immersive media with AVKit](/documentation/AVKit/playing-immersive-media-with-avkit)

Adopt the system playback interface to provide an immersive video watching experience.

Beta

[

Playing immersive media with RealityKit](/documentation/visionOS/playing-immersive-media-with-realitykit)

Create an immersive video playback experience with RealityKit.

Beta

[

Presenting images in RealityKit](/documentation/RealityKit/presenting-images-in-realitykit)

Create and display spatial scenes in RealityKit.

[

Processing a texture in a compute function](/documentation/Metal/processing-a-texture-in-a-compute-function)

Create textures by running copy and dispatch commands in a compute pass on a GPU.

Beta

[

Recognizing tables within a document](/documentation/Vision/recognize-tables-within-a-document)

Scan a document containing a contact table and extract the content within the table in a formatted way.

Beta

[

Rendering hover effects in Metal immersive apps](/documentation/CompositorServices/rendering_hover_effects_in_metal_immersive_apps)

Change the appearance of a rendered onscreen element when a player gazes at it.

Beta

[

Scheduling an alarm with AlarmKit](/documentation/AlarmKit/scheduling-an-alarm-with-alarmkit)

Create prominent alerts at specified dates for your iOS app.

Beta

[

Searching, displaying, and navigating to places](/documentation/MapKit/searching-displaying-and-navigating-to-places)

Convert place information between coordinates and user-friendly place names, get cycling directions, and conveniently display formatted addresses.

[

Supporting real-time ML inference on the CPU](/documentation/Accelerate/supporting-real-time-ml-inference-on-the-cpu)

Add real-time digital signal processing to apps like Logic Pro X and GarageBand with the BNNS Graph API.

Beta

[

Synchronizing group gameplay with TabletopKit](/documentation/TabletopKit/synchronizing-group-gameplay-with-tabletopkit)

Maintain game state across multiple players in a race to capture all the coins.

Beta

[

Tracking a handheld accessory as a virtual sculpting tool](/documentation/ARKit/tracking-a-handheld-accessory-as-a-virtual-sculpting-tool)

Use a tracked accessory with Apple Vision Pro to create a virtual sculpture.

Beta

[

Tracking accessories in volumetric windows](/documentation/ARKit/tracking-accessories-in-volumetric-windows)

Translate the position and velocity of tracked handheld accessories to throw virtual balls at a stack of cans.

Beta

[

Understanding StoreKit workflows](/documentation/StoreKit/understanding-storekit-workflows)

Implement an in-app store with several product types, using StoreKit views.

Beta

[

Using a Render Pipeline to Render Primitives](/documentation/Metal/using-a-render-pipeline-to-render-primitives)

Render a colorful, 2D triangle by running a draw command on the GPU.

[

Using the quantum-secure APIs](/documentation/CryptoKit/using-the-quantum-secure-apis)

Enhance your app’s privacy and security by using quantum-secure workflows.

Beta

### [Accelerate](/documentation/samplecode/#Accelerate)

[

Adding a bokeh effect to images](/documentation/Accelerate/adding-a-bokeh-effect-to-images)

Simulate a bokeh effect by applying dilation.

[

Adjusting saturation and applying tone mapping](/documentation/Accelerate/adjusting-saturation-and-applying-tone-mapping)

Convert an RGB image to discrete luminance and chrominance channels, and apply color and contrast treatments.

[

Adjusting the brightness and contrast of an image](/documentation/Accelerate/adjusting-the-brightness-and-contrast-of-an-image)

Use a gamma function to apply a linear or exponential curve.

[

Adjusting the hue of an image](/documentation/Accelerate/adjusting-the-hue-of-an-image)

Convert an image to L\*a\*b\* color space and apply hue adjustment.

[

Applying biquadratic filters to a music loop](/documentation/Accelerate/applying-biquadratic-filters-to-a-music-loop)

Change the frequency response of an audio signal using a cascaded biquadratic filter.

[

Applying tone curve adjustments to images](/documentation/Accelerate/applying-tone-curve-adjustments-to-images)

Use the vImage library’s polynomial transform to apply tone curve adjustments to images.

[

Applying transformations to selected colors in an image](/documentation/Accelerate/applying-transformations-to-selected-colors-in-an-image)

Desaturate a range of colors in an image with a multidimensional lookup table.

[

Applying vImage operations to video sample buffers](/documentation/Accelerate/applying-vimage-operations-to-video-sample-buffers)

Use the vImage convert-any-to-any functionality to perform real-time image processing of video frames streamed from your device’s camera.

[

Blurring an image](/documentation/Accelerate/blurring-an-image)

Filter an image by convolving it with custom and high-speed kernels.

[

Calculating the dominant colors in an image](/documentation/Accelerate/calculating-the-dominant-colors-in-an-image)

Find the main colors in an image by implementing k-means clustering using the Accelerate framework.

[

Compressing and decompressing files with stream compression](/documentation/Accelerate/compressing-and-decompressing-files-with-stream-compression)

Perform compression for all files and decompression for files with supported extension types.

[

Compressing an image using linear algebra](/documentation/Accelerate/compressing-an-image-using-linear-algebra)

Reduce the storage size of an image using singular value decomposition (SVD).

[

Converting color images to grayscale](/documentation/Accelerate/converting-color-images-to-grayscale)

Convert an RGB image to grayscale using matrix multiplication.

[

Converting luminance and chrominance planes to an ARGB image](/documentation/Accelerate/converting-luminance-and-chrominance-planes-to-an-argb-image)

Create a displayable ARGB image using the luminance and chrominance information from your device’s camera.

[

Creating an audio unit extension using the vDSP library](/documentation/Accelerate/creating-an-audio-unit-extension-using-the-vdsp-library)

Add biquadratic filter audio-effect processing to apps like Logic Pro X and GarageBand with the Accelerate framework.

[

Cropping to the subject in a chroma-keyed image](/documentation/Accelerate/cropping-to-the-subject-in-a-chroma-keyed-image)

Convert a chroma-key color to alpha values and trim transparent pixels using Accelerate.

[

Equalizing audio with discrete cosine transforms (DCTs)](/documentation/Accelerate/equalizing-audio-with-discrete-cosine-transforms-dcts)

Change the frequency response of an audio signal by manipulating frequency-domain data.

[

Finding the sharpest image in a sequence of captured images](/documentation/Accelerate/finding-the-sharpest-image-in-a-sequence-of-captured-images)

Share image data between vDSP and vImage to compute the sharpest image from a bracketed photo sequence.

[

Halftone descreening with 2D fast Fourier transform](/documentation/Accelerate/halftone-descreening-with-2d-fast-fourier-transform)

Reduce or remove periodic artifacts from images.

[

Improving the quality of quantized images with dithering](/documentation/Accelerate/improving-the-quality-of-quantized-images-with-dithering)

Apply dithering to simulate colors that are unavailable in reduced bit depths.

[

Integrating vImage pixel buffers into a Core Image workflow](/documentation/Accelerate/integrating-vimage-pixel-buffers-into-a-core-image-workflow)

Share image data between Core Video pixel buffers and vImage buffers to integrate vImage operations into a Core Image workflow.

[

Reducing artifacts with custom resampling filters](/documentation/Accelerate/reducing-artifacts-with-custom-resampling-filters)

Implement custom linear interpolation to prevent the ringing effects associated with scaling an image with the default Lanczos algorithm.

[

Rotating a cube by transforming its vertices](/documentation/Accelerate/rotating-a-cube-by-transforming-its-vertices)

Rotate a cube through a series of keyframes using quaternion interpolation to transition between them.

[

Sharing texture data between the Model I/O framework and the vImage library](/documentation/Accelerate/sharing-texture-data-between-the-model-io-framework-and-the-vimage-library)

Use Model I/O and vImage to composite a photograph over a computer-generated sky.

[

Signal extraction from noise](/documentation/Accelerate/signal-extraction-from-noise)

Use Accelerate’s discrete cosine transform to remove noise from a signal.

[

Solving systems of linear equations with LAPACK](/documentation/Accelerate/solving-systems-of-linear-equations-with-lapack)

Select the optimal LAPACK routine to solve a system of linear equations.

[

Specifying histograms with vImage](/documentation/Accelerate/specifying-histograms-with-vimage)

Calculate the histogram of one image, and apply it to a second image.

[

Training a neural network to recognize digits](/documentation/Accelerate/training-a-neural-network-to-recognize-digits)

Build a simple neural network and train it to recognize randomly generated numbers.

[

Using vImage pixel buffers to generate video effects](/documentation/Accelerate/using-vimage-pixel-buffers-to-generate-video-effects)

Render real-time video effects with the vImage Pixel Buffer.

[

Visualizing sound as an audio spectrogram](/documentation/Accelerate/visualizing-sound-as-an-audio-spectrogram)

Share image data between vDSP and vImage to visualize audio that a device microphone captures.

### [Accessibility](/documentation/samplecode/#Accessibility)

[

Accessibility design for Mac Catalyst](/documentation/Accessibility/accessibility_design_for_mac_catalyst)

Improve navigation in your app by using keyboard shortcuts and accessibility containers.

[

Delivering an exceptional accessibility experience](/documentation/Accessibility/delivering_an_exceptional_accessibility_experience)

Make improvements to your app’s interaction model to support assistive technologies such as VoiceOver.

[

Enhancing the accessibility of your SwiftUI app](/documentation/Accessibility/enhancing-the-accessibility-of-your-swiftui-app)

Support advancements in SwiftUI accessibility to make your app accessible to everyone.

[

Integrating accessibility into your app](/documentation/Accessibility/integrating_accessibility_into_your_app)

Make your app more accessible to users with disabilities by adding accessibility features.

[

Responding to changes in the flashing lights setting](/documentation/MediaAccessibility/responding-to-changes-in-the-flashing-lights-setting)

Adjust your UI when a person chooses to dim flashing lights on their Apple device.

[

Translating text within your app](/documentation/Translation/translating-text-within-your-app)

Display simple system translations and create custom translation experiences.

[

WWDC21 Challenge: Large Text Challenge](/documentation/Accessibility/wwdc21_challenge_large_text_challenge)

Design for large text sizes by modifying the user interface.

[

WWDC21 Challenge: Speech Synthesizer Simulator](/documentation/Accessibility/wwdc21_challenge_speech_synthesizer_simulator)

Simulate a conversation using speech synthesis.

[

WWDC21 Challenge: VoiceOver Maze](/documentation/Accessibility/wwdc21_challenge_voiceover_maze)

Navigate to the end of a dark maze using VoiceOver as your guide.

[

WWDC22 Challenge: Learn Switch Control through gaming](/documentation/Accessibility/wwdc22_challenge_learn_switch_control_through_gaming)

Play a card-matching game using Switch Control.

### [App frameworks](/documentation/samplecode/#App-frameworks)

[

Building a Localized Food-Ordering App](/documentation/foundation/building_a_localized_food-ordering_app)

Format, style, and localize your app’s text for use in multiple languages with string formatting, attributed strings, and automatic grammar agreement.

[

Building a resumable upload server with SwiftNIO](/documentation/Foundation/building-a-resumable-upload-server-with-swiftnio)

Support HTTP resumable upload protocol in SwiftNIO by translating resumable uploads to regular uploads.

[

Continuing User Activities with Handoff](/documentation/Foundation/continuing-user-activities-with-handoff)

Define and manage which of your app’s activities can be continued between devices.

[

Displaying Human-Friendly Content](/documentation/foundation/displaying_human-friendly_content)

Convert data into readable strings or Swift objects using formatters.

[

Displaying Searchable Content by Using a Search Controller](/documentation/uikit/view_controllers/displaying_searchable_content_by_using_a_search_controller)

Create a user interface with searchable content in a table view.

[

Fruta: Building a Feature-Rich App with SwiftUI](/documentation/appclip/fruta_building_a_feature-rich_app_with_swiftui)

Create a shared codebase to build a multiplatform app that offers widgets and an App Clip.

[

Increasing App Usage with Suggestions Based on User Activities](/documentation/foundation/task_management/increasing_app_usage_with_suggestions_based_on_user_activities)

Provide a continuous user experience by capturing information from your app and displaying this information as proactive suggestions across the system.

[

Interacting with App Clip Codes in AR](/documentation/AppClip/interacting-with-app-clip-codes-in-ar)

Display content and provide services in an AR experience with App Clip Codes.

[

Synchronizing App Preferences with iCloud](/documentation/foundation/icloud/synchronizing_app_preferences_with_icloud)

Store app preferences in iCloud and share them among instances of your app running on a user’s connected devices.

[

Using JSON with Custom Types](/documentation/foundation/archives_and_serialization/using_json_with_custom_types)

Encode and decode JSON data, regardless of its structure, using Swift’s JSON support.

### [App Intents and SiriKit](/documentation/samplecode/#App-Intents-and-SiriKit)

[

Accelerating app interactions with App Intents](/documentation/AppIntents/AcceleratingAppInteractionsWithAppIntents)

Enable people to use your app’s features quickly through Siri, Spotlight, and Shortcuts.

[

Adding Shortcuts for Wind Down](/documentation/SiriKit/adding-shortcuts-for-wind-down)

Reveal your app’s shortcuts inside the Health app.

[

Booking Rides with SiriKit](/documentation/SiriKit/booking-rides-with-sirikit)

Add Intents extensions to your app to handle requests to book rides using Siri and Maps.

[

Defining your app’s Focus filter](/documentation/appintents/focus/defining_your_app_s_focus_filter)

Customize your app’s behavior to reflect the device’s current Focus.

[

Handling Payment Requests with SiriKit](/documentation/SiriKit/handling-payment-requests-with-sirikit)

Add an Intent Extension to your app to handle money transfer requests with Siri.

[

Handling Workout Requests with SiriKit](/documentation/SiriKit/handling-workout-requests-with-sirikit)

Add an Intent Extension to your app that handles requests to control workouts with Siri.

[

Integrating Your App with Siri Event Suggestions](/documentation/SiriKit/integrating-your-app-with-siri-event-suggestions)

Donate reservations and provide quick access to event details throughout the system.

[

Making your app’s functionality available to Siri](/documentation/AppIntents/making-your-app-s-functionality-available-to-siri)

Add assistant schemas to your app so Siri can complete requests, and integrate your app with Apple Intelligence, Spotlight, and other system experiences.

[

Managing Audio with SiriKit](/documentation/SiriKit/managing-audio-with-sirikit)

Control audio playback and handle requests to add media using SiriKit Media Intents.

[

Providing Hands-Free App Control with Intents](/documentation/SiriKit/providing-hands-free-app-control-with-intents)

Resolve, confirm, and handle intents without an extension.

[

Soup Chef: Accelerating App Interactions with Shortcuts](/documentation/SiriKit/soup-chef-accelerating-app-interactions-with-shortcuts)

Make it easy for people to use Siri with your app by providing shortcuts to your app’s actions.

[

Soup Chef with App Intents: Migrating custom intents](/documentation/SiriKit/soup-chef-with-app-intents-migrating-custom-intents)

Integrating App Intents to provide your appʼs actions to Siri and Shortcuts.

### [AppKit](/documentation/samplecode/#AppKit)

[

Add Functionality to Finder with Action Extensions](/documentation/AppKit/add-functionality-to-finder-with-action-extensions)

Implement Action Extensions to provide quick access to commonly used features of your app.

[

Creating and Customizing the Touch Bar](/documentation/AppKit/creating-and-customizing-the-touch-bar)

Adopt Touch Bar support by displaying interactive content and controls for your macOS apps.

[

Creating self-sizing table view cells](/documentation/UIKit/creating-self-sizing-table-view-cells)

Create table view cells that support Dynamic Type and use system spacing constraints to adjust the spacing surrounding text labels.

[

Developing a Document-Based App](/documentation/AppKit/developing-a-document-based-app)

Write an app that creates, manages, edits, and saves text documents.

[

Implementing Modern Collection Views](/documentation/uikit/views_and_controls/collection_views/implementing_modern_collection_views)

Bring compositional layouts to your app and simplify updating your user interface with diffable data sources.

[

Integrating a Toolbar and Touch Bar into Your App](/documentation/AppKit/integrating-a-toolbar-and-touch-bar-into-your-app)

Provide users quick access to your app’s features from a toolbar and corresponding Touch Bar.

[

Navigating Hierarchical Data Using Outline and Split Views](/documentation/AppKit/navigating-hierarchical-data-using-outline-and-split-views)

Build a structured user interface that simplifies navigation in your app.

[

Organize Your User Interface with a Stack View](/documentation/AppKit/organize-your-user-interface-with-a-stack-view)

Group individual views in your app’s user interface into a scrollable stack view.

[

Supporting Collection View Drag and Drop Through File Promises](/documentation/AppKit/supporting-collection-view-drag-and-drop-through-file-promises)

Share data between macOS apps during drag and drop by using an item provider.

[

Supporting Drag and Drop Through File Promises](/documentation/AppKit/supporting-drag-and-drop-through-file-promises)

Receive and provide file promises to support dragged app files and pasteboard operations.

[

Supporting Table View Drag and Drop Through File Promises](/documentation/AppKit/supporting-table-view-drag-and-drop-through-file-promises)

Share data between macOS apps during drag and drop by using an item provider.

### [App services](/documentation/samplecode/#App-services)

[

Accessing a person’s contact data using Contacts and ContactsUI](/documentation/Contacts/accessing-a-person-s-contact-data-using-contacts-and-contactsui)

Allow people to grant your app access to contact data by adding the Contact access button and Contact access picker to your app.

[

Accessing Calendar using EventKit and EventKitUI](/documentation/EventKit/accessing-calendar-using-eventkit-and-eventkitui)

Choose and implement the appropriate Calendar access level in your app.

[

Adopting SwiftData for a Core Data app](/documentation/CoreData/adopting-swiftdata-for-a-core-data-app)

Persist data in your app intuitively with the Swift native persistence framework.

[

Build an Educational Assessment App](/documentation/AutomaticAssessmentConfiguration/build-an-educational-assessment-app)

Ensure the academic integrity of your assessment app by using Automatic Assessment Configuration.

[

Build Mail App Extensions](/documentation/MailKit/build-mail-app-extensions)

Create app extensions that block content, perform message and composing actions, and help message security.

[

Checking IDs with the Verifier API](/documentation/ProximityReader/checking-ids-with-the-verifier-api)

Read and verify mobile driver’s license information without any additional hardware.

[

Configuring a home automation device](/documentation/HomeKit/configuring-a-home-automation-device)

Give users a familiar experience when they manage HomeKit accessories.

[

Configuring the PencilKit tool picker](/documentation/PencilKit/configuring-the-pencilkit-tool-picker)

Incorporate a custom PencilKit tool picker with a variety of system and custom tools into a drawing app.

[

Creating a data visualization dashboard with Swift Charts](/documentation/Charts/creating-a-data-visualization-dashboard-with-swift-charts)

Visualize an entire data collection efficiently by instantiating a single vectorized plot in Swift Charts.

[

Creating a Sticker App with a Custom Layout](/documentation/Messages/creating-a-sticker-app-with-a-custom-layout)

Expand on the Messages sticker app template to create an app with a customized user interface.

[

Customizing Scribble with Interactions](/documentation/PencilKit/customizing-scribble-with-interactions)

Enable writing on a non-text-input view by adding interactions.

[

Downloading essential assets in the background](/documentation/BackgroundAssets/downloading-essential-assets-in-the-background)

Fetch the assets your app requires before its first launch using an app extension and the Background Assets framework.

[

Drawing with PencilKit](/documentation/PencilKit/drawing-with-pencilkit)

Add expressive, low-latency drawing to your app using PencilKit.

[

Example Order Packages](/documentation/WalletOrders/example-order-packages)

Edit, build, and add example order packages to Wallet.

[

Fetching weather forecasts with WeatherKit](/documentation/weatherkit/fetching_weather_forecasts_with_weatherkit)

Request and display weather data for destination airports in a flight-planning app.

[

Handling Communication Notifications and Focus Status Updates](/documentation/UserNotifications/handling-communication-notifications-and-focus-status-updates)

Create a richer calling and messaging experience in your app by implementing communication notifications and Focus status updates.

[

Handling Different Data Types in Core Data](/documentation/CoreData/handling-different-data-types-in-core-data)

Create, store, and present records for a variety of data types.

[

Highlighting app features with TipKit](/documentation/TipKit/HighlightingAppFeaturesWithTipKit)

Bring attention to new features in your app by using tips.

[

IceCreamBuilder: Building an iMessage Extension](/documentation/Messages/icecreambuilder-building-an-imessage-extension)

Allow users to collaborate on the design of ice cream sundae stickers.

[

Implementing Alert Push Notifications](/documentation/UserNotifications/implementing-alert-push-notifications)

Add visible alert notifications to your app by using the UserNotifications framework.

[

Implementing Background Push Notifications](/documentation/UserNotifications/implementing-background-push-notifications)

Add background notifications to your app by using the UserNotifications framework.

[

Implementing Wallet Extensions](/documentation/PassKit/implementing-wallet-extensions)

Support adding an issued card to Apple Pay from directly within Apple Wallet using Wallet Extensions.

[

Incorporating ClassKit into an Educational App](/documentation/ClassKit/incorporating-classkit-into-an-educational-app)

Walk through the process of setting up assignments and recording student progress.

[

Inspecting, Modifying, and Constructing PencilKit Drawings](/documentation/PencilKit/inspecting-modifying-and-constructing-pencilkit-drawings)

Score users’ ability to match PencilKit drawings generated from text, by accessing the strokes and points inside PencilKit drawings.

[

Integrating the Apple Maps Server API into Java server applications](/documentation/AppleMapsServerAPI/integrating-the-apple-maps-server-api-into-java-server-applications)

Streamline your app’s API by moving georelated searches from inside your app to your server.

[

Interacting with a home automation network](/documentation/HomeKit/interacting-with-a-home-automation-network)

Find all the automation accessories in the primary home and control their state.

[

Linking Data Between Two Core Data Stores](/documentation/CoreData/linking-data-between-two-core-data-stores)

Organize data in two different stores and implement a link between them.

[

Managing location-based reminders](/documentation/EventKit/managing-location-based-reminders)

Access reminders set up with geofence-enabled alarms on a person’s calendars.

[

Offering Apple Pay in Your App](/documentation/PassKit/offering-apple-pay-in-your-app)

Collect payments with iPhone and Apple Watch using Apple Pay.

[

Refreshing and Maintaining Your App Using Background Tasks](/documentation/BackgroundTasks/refreshing-and-maintaining-your-app-using-background-tasks)

Use scheduled background tasks for refreshing your app content and for performing maintenance.

[

Sharing CloudKit Data with Other iCloud Users](/documentation/CloudKit/sharing-cloudkit-data-with-other-icloud-users)

Create and share private CloudKit data with other users by implementing the sharing UI.

[

Sharing Core Data objects between iCloud users](/documentation/CoreData/sharing-core-data-objects-between-icloud-users)

Use Core Data and CloudKit to synchronize data between devices of an iCloud user and share data between different iCloud users.

[

Showcase App Data in Spotlight](/documentation/CoreData/showcase-app-data-in-spotlight)

Index app data so users can find it by using Spotlight search.

[

Synchronizing a local store to the cloud](/documentation/CoreData/synchronizing-a-local-store-to-the-cloud)

Share data between a user’s devices and other iCloud users.

[

Synchronizing files using file provider extensions](/documentation/FileProvider/synchronizing-files-using-file-provider-extensions)

Make remote files available in macOS and iOS, and synchronize their states by using file provider extensions.

[

Updating your app package installer to use the new Service Management API](/documentation/ServiceManagement/updating-your-app-package-installer-to-use-the-new-service-management-api)

Learn about the Service Management API with a GUI-less agent app.

[

Visualizing your app’s data](/documentation/charts/visualizing_your_app_s_data)

Build complex and interactive charts using Swift Charts.

[

VoIP calling with CallKit](/documentation/CallKit/voip-calling-with-callkit)

Use the CallKit framework to integrate native VoIP calling.

### [ARKit](/documentation/samplecode/#ARKit)

[

Adding realistic reflections to an AR experience](/documentation/ARKit/adding-realistic-reflections-to-an-ar-experience)

Use ARKit to generate environment probe textures from camera imagery and render reflective virtual objects.

[

Building local experiences with room tracking](/documentation/arkit/building_local_experiences_with_room_tracking)

Use room tracking in visionOS to provide custom interactions with physical spaces.

[

Capturing Body Motion in 3D](/documentation/ARKit/capturing-body-motion-in-3d)

Track a person in the physical environment and visualize their motion by applying the same body movements to a virtual character.

[

Combining user face-tracking and world tracking](/documentation/ARKit/combining-user-face-tracking-and-world-tracking)

Track the user’s face in an app that displays an AR experience with the rear camera.

[

Creating a collaborative session](/documentation/ARKit/creating-a-collaborative-session)

Enable nearby devices to share an AR experience by using a peer-to-peer multiuser strategy.

[

Creating a fog effect using scene depth](/documentation/ARKit/creating-a-fog-effect-using-scene-depth)

Apply virtual fog to the physical environment.

[

Creating a multiuser AR experience](/documentation/ARKit/creating-a-multiuser-ar-experience)

Enable nearby devices to share an AR experience by using a host-guest multiuser strategy.

[

Creating an immersive ar experience with audio](/documentation/ARKit/creating-an-immersive-ar-experience-with-audio)

Use sound effects and environmental sound layers to create an engaging AR experience.

[

Creating screen annotations for objects in an AR experience](/documentation/ARKit/creating-screen-annotations-for-objects-in-an-ar-experience)

Annotate an AR experience with virtual sticky notes that you display onscreen over real and virtual objects.

[

Detecting Images in an AR Experience](/documentation/ARKit/detecting-images-in-an-ar-experience)

React to known 2D images in the user’s environment, and use their positions to place AR content.

[

Displaying a point cloud using scene depth](/documentation/ARKit/displaying-a-point-cloud-using-scene-depth)

Present a visualization of the physical environment by placing points based a scene’s depth data.

[

Effecting People Occlusion in Custom Renderers](/documentation/ARKit/effecting-people-occlusion-in-custom-renderers)

Occlude your app’s virtual content where ARKit recognizes people in the camera feed by using matte generator.

[

Occluding virtual content with people](/documentation/ARKit/occluding-virtual-content-with-people)

Cover your app’s virtual content with people that ARKit perceives in the camera feed.

[

Placing objects and handling 3D interaction](/documentation/ARKit/placing-objects-and-handling-3d-interaction)

Place virtual content at tracked, real-world locations, and enable the user to interact with virtual content by using gestures.

[

Recognizing and Labeling Arbitrary Objects](/documentation/ARKit/recognizing-and-labeling-arbitrary-objects)

Create anchors that track objects you recognize in the camera feed, using a custom optical-recognition algorithm.

[

Saving and loading world data](/documentation/ARKit/saving-and-loading-world-data)

Serialize a world-tracking session to resume it later on.

[

Scanning and Detecting 3D Objects](/documentation/ARKit/scanning-and-detecting-3d-objects)

Record spatial features of real-world objects, then use the results to find those objects in the user’s environment and trigger AR content.

[

Schema definitions for third-party DCCs](/documentation/arkit/schema_definitions_for_third-party_dccs)

Update your local USD library to add interactive and augmented reality features.

[

Streaming an AR experience](/documentation/ARKit/streaming-an-ar-experience)

Control an AR experience remotely by transferring sensor and user input over the network.

[

Tracking and altering images](/documentation/ARKit/tracking-and-altering-images)

Create images from rectangular shapes found in the user’s environment, and augment their appearance.

[

Tracking and visualizing faces](/documentation/ARKit/tracking-and-visualizing-faces)

Detect faces in a front-camera AR experience, overlay virtual content, and animate facial expressions in real-time.

[

Tracking and visualizing planes](/documentation/ARKit/tracking-and-visualizing-planes)

Detect surfaces in the physical environment and visualize their shape and location in 3D space.

[

Tracking geographic locations in AR](/documentation/ARKit/tracking-geographic-locations-in-ar)

Track specific geographic areas of interest and render them in an AR experience.

[

Visualizing and interacting with a reconstructed scene](/documentation/ARKit/visualizing-and-interacting-with-a-reconstructed-scene)

Estimate the shape of the physical environment using a polygonal mesh.

### [Audio and music](/documentation/samplecode/#Audio-and-music)

[

Adding synthesized speech to calls](/documentation/AVFAudio/Adding-synthesized-speech-to-calls)

Provide a more accessible experience by adding your app’s audio to a call.

[

Becoming a now playable app](/documentation/MediaPlayer/becoming-a-now-playable-app)

Ensure your app is eligible to become the Now Playing app by adopting best practices for providing Now Playing info and registering for remote command center actions.

[

Building a Custom Catalog and Matching Audio](/documentation/ShazamKit/building-a-custom-catalog-and-matching-audio)

Display lesson content that’s synchronized to a learning video by matching the audio to a custom reference signature and associated metadata.

[

Building an Audio Server Plug-in and Driver Extension](/documentation/CoreAudio/building-an-audio-server-plug-in-and-driver-extension)

Create a plug-in and driver extension to support an audio device in macOS.

[

Building a signal generator](/documentation/AVFAudio/building-a-signal-generator)

Use an audio source node and a custom render callback to generate audio signals.

[

Capturing stereo audio from built-In microphones](/documentation/AVFAudio/capturing-stereo-audio-from-built-in-microphones)

Configure an iOS device’s built-in microphones to add stereo recording capabilities to your app.

[

Capturing system audio with Core Audio taps](/documentation/CoreAudio/capturing-system-audio-with-core-audio-taps)

Use a Core Audio tap to capture outgoing audio from a process or group of processes.

[

Classifying Live Audio Input with a Built-in Sound Classifier](/documentation/SoundAnalysis/classifying-live-audio-input-with-a-built-in-sound-classifier)

Detect and identify hundreds of sounds by using a trained classifier.

[

Creating a custom speech synthesizer](/documentation/AVFAudio/creating-a-custom-speech-synthesizer)

Use your custom voices to synthesize speech by building a speech synthesis provider.

[

Creating an audio device driver](/documentation/AudioDriverKit/creating-an-audio-device-driver)

Implement a configurable audio input source as a driver extension that runs in user space in macOS and iPadOS.

[

Creating an Audio Server Driver Plug-in](/documentation/CoreAudio/creating-an-audio-server-driver-plug-in)

Build a virtual audio device by creating a custom driver plug-in.

[

Creating custom audio effects](/documentation/AVFAudio/creating-custom-audio-effects)

Add custom audio-effect processing to apps like Logic Pro X and GarageBand by creating Audio Unit (AU) plug-ins.

[

Delivering Rich App Experiences with Haptics](/documentation/CoreHaptics/delivering-rich-app-experiences-with-haptics)

Enhance your app’s experience by incorporating haptic and sound feedback into key interactive moments.

[

Discovering a third-party media-streaming device](/documentation/DeviceDiscoveryExtension/discovering-a-third-party-media-streaming-device)

Build an extension that streams media to a server app in iOS or macOS.

[

Encoding and decoding audio](/documentation/AudioToolbox/encoding-and-decoding-audio)

Convert audio formats to efficiently manage data and quality.

[

Explore more content with MusicKit](/documentation/musickit/explore_more_content_with_musickit)

Track your outdoor runs with access to the Apple Music catalog, personal recommendations, and your own personal music library.

[

Generating spatial audio from a multichannel audio stream](/documentation/AudioToolbox/generating-spatial-audio-from-a-multichannel-audio-stream)

Convert 8-channel audio to 2-channel spatial audio by using a spatial mixer audio unit.

[

Getting motion-activity data from headphones](/documentation/CoreMotion/getting-motion-activity-data-from-headphones)

Configure your app to listen for motion-activity changes from headphones.

[

Incorporating Audio Effects and Instruments](/documentation/AudioToolbox/incorporating-audio-effects-and-instruments)

Add custom audio processing and MIDI instruments to your app by hosting Audio Unit (AU) plug-ins.

[

Incorporating MIDI 2 into your apps](/documentation/CoreMIDI/incorporating-midi-2-into-your-apps)

Add precision and improve musical control for your MIDI apps.

[

Integrating CarPlay with Your Music App](/documentation/CarPlay/integrating-carplay-with-your-music-app)

Configure your music app to work with CarPlay by displaying a custom UI.

[

Integrating CarPlay with Your Navigation App](/documentation/CarPlay/integrating-carplay-with-your-navigation-app)

Configure your navigation app to work with CarPlay by displaying your custom map and directions.

[

Integrating CarPlay with your quick-ordering app](/documentation/CarPlay/integrating-carplay-with-your-quick-ordering-app)

Configure your food-ordering app to work with CarPlay.

[

Performing offline audio processing](/documentation/AVFAudio/performing-offline-audio-processing)

Add offline audio processing features to your app by enabling offline manual rendering mode.

[

Playing a Custom Haptic Pattern from a File](/documentation/CoreHaptics/playing-a-custom-haptic-pattern-from-a-file)

Sample predesigned Apple Haptic Audio Pattern files, and learn how to play your own.

[

Playing Collision-Based Haptic Patterns](/documentation/CoreHaptics/playing-collision-based-haptic-patterns)

Play a custom haptic pattern whose strength depends on an object’s collision speed.

[

Playing custom audio with your own player](/documentation/AVFAudio/playing-custom-audio-with-your-own-player)

Construct an audio player to play your custom audio data, and optionally take advantage of the advanced features of AirPlay 2.

[

Playing Haptics on Game Controllers](/documentation/CoreHaptics/playing-haptics-on-game-controllers)

Add haptic feedback to supported game controllers by using Core Haptics.

[

Recognizing speech in live audio](/documentation/Speech/recognizing-speech-in-live-audio)

Perform speech recognition on audio coming from the microphone of an iOS device.

[

ShazamKit Dance Finder with Managed Session](/documentation/ShazamKit/shazamkit-dance-finder-with-managed-session)

Find a video of dance moves for a specific song by matching the audio to a custom catalog, and show a history of recognized songs.

[

Transferring Data Between Bluetooth Low Energy Devices](/documentation/CoreBluetooth/transferring-data-between-bluetooth-low-energy-devices)

Create a Bluetooth low energy central and peripheral device, and allow them to discover each other and exchange data.

[

Updating Continuous and Transient Haptic Parameters in Real Time](/documentation/CoreHaptics/updating-continuous-and-transient-haptic-parameters-in-real-time)

Generate continuous and transient haptic patterns in response to user touch.

[

Using Core Bluetooth Classic](/documentation/CoreBluetooth/using-core-bluetooth-classic)

Discover and communicate with a Bluetooth Classic device by using the Core Bluetooth APIs.

[

Using MusicKit to Integrate with Apple Music](/documentation/musickit/using_musickit_to_integrate_with_apple_music)

Find an album in Apple Music that corresponds to a CD in a user’s collection, and present the information for the album.

[

Using voice processing](/documentation/AVFAudio/using-voice-processing)

Add voice-processing capabilities to your app by using audio engine.

### [Authentication](/documentation/samplecode/#Authentication)

[

Accessing Keychain Items with Face ID or Touch ID](/documentation/LocalAuthentication/accessing-keychain-items-with-face-id-or-touch-id)

Protect a keychain item with biometric authentication.

[

Connecting to a service with passkeys](/documentation/AuthenticationServices/connecting-to-a-service-with-passkeys)

Allow users to sign in to a service without typing a password.

[

Implementing User Authentication with Sign in with Apple](/documentation/AuthenticationServices/implementing-user-authentication-with-sign-in-with-apple)

Provide a way for users of your app to set up an account and start using your services.

[

Logging a User into Your App with Face ID or Touch ID](/documentation/LocalAuthentication/logging-a-user-into-your-app-with-face-id-or-touch-id)

Supplement your own authentication scheme with biometric authentication, making it easy for users to access sensitive parts of your app.

[

Simplifying User Authentication in a tvOS App](/documentation/AuthenticationServices/simplifying-user-authentication-in-a-tvos-app)

Build a fluid sign-in experience for your tvOS apps using AuthenticationServices.

### [AVFoundation](/documentation/samplecode/#AVFoundation)

[

AVCam: Building a camera app](/documentation/AVFoundation/avcam-building-a-camera-app)

Capture photos and record video using the front and rear iPhone and iPad cameras.

Beta

[

AVCamBarcode: Detecting Barcodes and Faces](/documentation/AVFoundation/avcambarcode-detecting-barcodes-and-faces)

Identify machine readable codes or faces by using the camera.

[

AVCamFilter: Applying Filters to a Capture Stream](/documentation/AVFoundation/avcamfilter-applying-filters-to-a-capture-stream)

Render a capture stream with rose-colored filtering and depth effects.

[

AVMultiCamPiP: Capturing from Multiple Cameras](/documentation/AVFoundation/avmulticampip-capturing-from-multiple-cameras)

Simultaneously record the output from the front and back cameras into a single movie file by using a multi-camera capture session.

[

Building a Signal Generator](/documentation/avfoundation/building_a_signal_generator)

Use an audio source node and a custom render callback to generate audio signals.

[

Capturing consistent color images](/documentation/AVFoundation/capturing-consistent-color-images)

Add the power of a photography studio and lighting rig to your app with the new Constant Color API.

[

Capturing depth using the LiDAR camera](/documentation/AVFoundation/capturing-depth-using-the-lidar-camera)

Access the LiDAR camera on supporting devices to capture precise depth data.

[

Capturing stereo audio from built-in microphones](/documentation/avfaudio/capturing_stereo_audio_from_built-in_microphones)

Configure an iOS device’s built-in microphones to add stereo-recording capabilities to your app.

[

Converting side-by-side 3D video to multiview HEVC and spatial video](/documentation/AVFoundation/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video)

Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.

[

Creating Custom Audio Effects](/documentation/avfoundation/creating_custom_audio_effects)

Add custom audio-effect processing to apps like Logic Pro X and GarageBand by creating Audio Unit (AU) plug-ins.

[

Debugging AVFoundation audio mixes, compositions, and video compositions](/documentation/AVFoundation/debugging-avfoundation-audio-mixes-compositions-and-video-compositions)

Resolve common problems when creating compositions, video compositions, and audio mixes.

[

Editing and Playing HDR Video](/documentation/AVFoundation/editing-and-playing-hdr-video)

Support high-dynamic-range (HDR) video content in your app by using the HDR editing and playback capabilities of AVFoundation.

[

Enhancing Live Video by Leveraging TrueDepth Camera Data](/documentation/AVFoundation/enhancing-live-video-by-leveraging-truedepth-camera-data)

Apply your own background to a live capture feed streamed from the front-facing TrueDepth camera.

[

Integrating AirPlay for Long-Form Video Apps](/documentation/AVFoundation/integrating-airplay-for-long-form-video-apps)

Integrate AirPlay features and implement a dedicated external playback experience by preparing the routing system for long-form video playback.

[

Performing Offline Audio Processing](/documentation/avfoundation/performing_offline_audio_processing)

Add offline audio processing features to your app by enabling offline manual rendering mode.

[

Playing Custom Audio with Your Own Player](/documentation/avfaudio/audio_engine/playing_custom_audio_with_your_own_player)

Construct an audio player to play your custom audio data, and optionally take advantage of the advanced features of AirPlay 2.

[

Providing an integrated view of your timeline when playing HLS interstitials](/documentation/AVFoundation/providing-an-integrated-view-of-your-timeline-when-playing-hls-interstitials)

Go beyond simple ad insertion with point and fill occupancy HLS interstitials.

[

Reading multiview 3D video files](/documentation/AVFoundation/reading-multiview-3d-video-files)

Render single images for the left eye and right eye from a multiview High Efficiency Video Coding format file by reading individual video frames.

[

Streaming Depth Data from the TrueDepth Camera](/documentation/AVFoundation/streaming-depth-data-from-the-truedepth-camera)

Visualize depth data in 2D and 3D from the TrueDepth camera.

[

Supporting Continuity Camera in your macOS app](/documentation/AVFoundation/supporting-continuity-camera-in-your-macos-app)

Enable high-quality photo and video capture by using an iPhone camera as an external capture device.

[

Supporting Coordinated Media Playback](/documentation/AVFoundation/supporting-coordinated-media-playback)

Create synchronized media experiences that enable users to watch and listen across devices.

[

Supporting remote interactions in tvOS](/documentation/AVFoundation/supporting-remote-interactions-in-tvos)

Set up your app to support remote commands and events in a variety of scenarios by using the relevant approach.

[

Using AVFoundation to play and persist HTTP Live Streams](/documentation/AVFoundation/using-avfoundation-to-play-and-persist-http-live-streams)

Play HTTP Live Streams and persist streams on disk for offline playback using AVFoundation.

[

Using HEVC Video with Alpha](/documentation/AVFoundation/using-hevc-video-with-alpha)

Play, write, and export HEVC video with an alpha channel to add overlay effects to your video processing.

[

Using Voice Processing](/documentation/avfoundation/using_voice_processing)

Add voice-processing capabilities to your app by using audio engine.

[

Writing Fragmented MPEG-4 Files for HTTP Live Streaming](/documentation/AVFoundation/writing-fragmented-mpeg-4-files-for-http-live-streaming)

Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.

### [CoreML and CreateML](/documentation/samplecode/#CoreML-and-CreateML)

[

Classifying Images with Vision and Core ML](/documentation/coreml/model_integration_samples/classifying_images_with_vision_and_core_ml)

Crop and scale photos using the Vision framework and classify them with a Core ML model.

[

Counting human body action repetitions in a live video feed](/documentation/createmlcomponents/counting_human_body_action_repetitions_in_a_live_video_feed)

Use Create ML Components to analyze a series of video frames and count a person’s repetitive or periodic body movements.

[

Creating a Model from Tabular Data](/documentation/createml/creating_a_model_from_tabular_data)

Train a machine learning model by using Core ML to import and manage tabular data.

[

Detecting Human Actions in a Live Video Feed](/documentation/createml/detecting_human_actions_in_a_live_video_feed)

Identify body movements by sending a person’s pose data from a series of video frames to an action-classification model.

[

Detecting human body poses in an image](/documentation/CoreML/detecting-human-body-poses-in-an-image)

Locate people and the stance of their bodies by analyzing an image with a PoseNet model.

[

Finding answers to questions in a text document](/documentation/CoreML/finding-answers-to-questions-in-a-text-document)

Locate relevant passages in a document by asking the Bidirectional Encoder Representations from Transformers (BERT) model a question.

[

Integrating a Core ML Model into Your App](/documentation/CoreML/integrating-a-core-ml-model-into-your-app)

Add a simple model to an app, pass input data to the model, and process the model’s predictions.

[

Personalizing a Model with On-Device Updates](/documentation/CoreML/personalizing-a-model-with-on-device-updates)

Modify an updatable Core ML model by running an update task with labeled data.

[

Understanding a Dice Roll with Vision and Object Detection](/documentation/coreml/model_integration_samples/understanding_a_dice_roll_with_vision_and_object_detection)

Detect dice position and values shown in a camera frame, and determine the end of a roll by leveraging a dice detection model.

[

Using Core ML for semantic image segmentation](/documentation/CoreML/using-core-ml-for-semantic-image-segmentation)

Identify multiple objects in an image by using the DEtection TRansformer image-segmentation model.

### [Developer tools](/documentation/samplecode/#Developer-tools)

[

Autosizing Views for Localization in iOS](/documentation/xcode/autosizing_views_for_localization_in_ios)

Add auto layout constraints to your app to achieve localizable views.

[

Configuring Your App to Use Alternate App Icons](/documentation/xcode/configuring_your_app_to_use_alternate_app_icons)

Add alternate app icons to your app, and let people choose which icon to display.

[

Creating custom modelers for intelligent instruments](/documentation/Xcode/creating-custom-modelers-for-intelligent-instruments)

Create Custom Modelers with the CLIPS language and learn how the embedded rules engine works.

[

Localization-Friendly Layouts in macOS](/documentation/xcode/localization-friendly_layouts_in_macos)

This project demonstrates localization-friendly auto layout constraints. It uses \`NSGridView\` as a container view to achieve localized layouts.

[

Providing touch gesture equivalents using Touch Alternatives](/documentation/Apple-Silicon/providing-touch-gesture-equivalents-using-touch-alternatives)

Enable Touch Alternatives to provide keyboard, mouse, and trackpad equivalents to your iOS app when it runs on a Mac with Apple silicon.

[

Providing an edge-to-edge, full-screen experience in your iPad app running on a Mac](/documentation/Apple-Silicon/providing-an-edge-to-edge-full-screen-experience-in-your-ipad-app-running-on-a-mac)

Take advantage of the true native resolution of a Mac display when running your iPad app in full-screen mode on a Mac.

[

SlothCreator: Building DocC Documentation in Xcode](/documentation/xcode/slothcreator_building_docc_documentation_in_xcode)

Build DocC documentation for a Swift package that contains a DocC Catalog.

### [Games](/documentation/samplecode/#Games)

[

Adding Recurring Leaderboards to Your Game](/documentation/GameKit/adding-recurring-leaderboards-to-your-game)

Encourage competition in your games by adding leaderboards that have a duration and repeat.

[

Creating real-time games](/documentation/GameKit/creating-real-time-games)

Develop games where multiple players interact in real time.

[

Creating tabletop games](/documentation/TabletopKit/TabletopKitSample)

Develop a spatial board game where multiple players interact with pieces on a table.

[

Creating turn-based games](/documentation/GameKit/creating-turn-based-games)

Develop games where multiple players take turns and can exchange data while waiting for their turn.

[

Interacting with virtual content blended with passthrough](/documentation/CompositorServices/interacting-with-virtual-content-blended-with-passthrough)

Present a mixed immersion style space to draw content in a person’s surroundings, and choose how upper limbs appear with respect to rendered content.

[

Supporting Game Controllers](/documentation/GameController/supporting-game-controllers)

Support a physical controller or add a virtual controller to enhance how people interact with your game through haptics, lighting, and motion sensing.

### [Graphics](/documentation/samplecode/#Graphics)

[

Building a Document Browser App for Custom File Formats](/documentation/uikit/view_controllers/building_a_document_browser_app_for_custom_file_formats)

Implement a custom document file format to manage user interactions with files on different cloud storage providers.

[

Building Widgets Using WidgetKit and SwiftUI](/documentation/widgetkit/building_widgets_using_widgetkit_and_swiftui)

Create widgets to show your app’s content on the Home screen, with custom intents for user-customizable settings.

[

Create a 3D model of an interior room by guiding the user through an AR experience](/documentation/RoomPlan/create-a-3d-model-of-an-interior-room-by-guiding-the-user-through-an-ar-experience)

Highlight physical structures and display text that guides a user to scan the shape of their physical environment using a framework-provided view.

[

Custom Graphics](/documentation/PDFKit/custom-graphics)

Demonstrates adding a watermark to a PDF page.

[

Emoji Rangers: Supporting Live Activities, interactivity, and animations](/documentation/WidgetKit/emoji-rangers-supporting-live-activities-interactivity-and-animations)

Offer Live Activities, controls, animate data updates, and add interactivity to widgets.

[

Generating an animation with a Core Image Render Destination](/documentation/CoreImage/generating-an-animation-with-a-core-image-render-destination)

Animate a filtered image to a Metal view in a SwiftUI app using a Core Image Render Destination.

[

Merging multiple scans into a single structure](/documentation/RoomPlan/merging-multiple-scans-into-a-single-structure)

Export a 3D model that consists of multiple rooms captured in the same physical vicinity.

[

PDF Widgets](/documentation/PDFKit/pdf-widgets)

Demonstrates adding widgets—interactive form elements—to a PDF document.

[

Postprocessing a Scene With Custom Symbols](/documentation/SceneKit/postprocessing-a-scene-with-custom-symbols)

Create visual effects in a scene by defining a rendering technique with custom symbols.

[

Providing custom models for captured rooms and structure exports](/documentation/RoomPlan/providing-custom-models-for-captured-rooms-and-structure-exports)

Enhance the look of an exported 3D model by substituting object bounding boxes with detailed 3D renditions.

[

Writing spatial photos](/documentation/ImageIO/writing-spatial-photos)

Create spatial photos for visionOS by packaging a pair of left- and right-eye images as a stereo HEIC file with related spatial metadata.

### [Health](/documentation/samplecode/#Health)

[

Accessing a User’s Clinical Records](/documentation/HealthKit/accessing-a-user-s-clinical-records)

Request authorization to query HealthKit for a user’s clinical records and display them in your app.

[

Accessing Data from a SMART Health Card](/documentation/HealthKit/accessing-data-from-a-smart-health-card)

Query for and validate a verifiable clinical record.

[

Build a workout app for Apple Watch](/documentation/HealthKit/build-a-workout-app-for-apple-watch)

Create your own workout app, quickly and easily, with HealthKit and SwiftUI.

[

Building a multidevice workout app](/documentation/HealthKit/building-a-multidevice-workout-app)

Mirror a workout from a watchOS app to its companion iOS app, and perform bidirectional communication between them.

[

Building an App to Notify Users of COVID-19 Exposure](/documentation/ExposureNotification/building-an-app-to-notify-users-of-covid-19-exposure)

Inform people when they may have been exposed to COVID-19.

[

Creating a Mobility Health App](/documentation/HealthKit/creating-a-mobility-health-app)

Create a health app that allows a clinical care team to send and receive mobility data.

[

Reading and Writing HealthKit Series Data](/documentation/HealthKit/reading-and-writing-healthkit-series-data)

Share and read heartbeat and quantity series data using series builders and queries.

[

Visualizing HealthKit State of Mind in visionOS](/documentation/HealthKit/visualizing-healthkit-state-of-mind-in-visionos)

Incorporate HealthKit State of Mind into your app and visualize the data in visionOS.

### [Location and MapKit](/documentation/samplecode/#Location-and-MapKit)

[

Adopting live updates in Core Location](/documentation/CoreLocation/adopting-live-updates-in-core-location)

Simplify location delivery using asynchronous events in Swift.

[

Annotating a Map with Custom Data](/documentation/MapKit/annotating-a-map-with-custom-data)

Annotate a map with location-specific data using default and customized annotation views and callouts.

[

Decluttering a Map with MapKit Annotation Clustering](/documentation/MapKit/decluttering-a-map-with-mapkit-annotation-clustering)

Enhance the readability of a map by replacing overlapping annotations with a clustering annotation view.

[

Displaying an Indoor Map](/documentation/MapKit/displaying-an-indoor-map)

Use the Indoor Mapping Data Format (IMDF) to show an indoor map with custom overlays and points of interest.

[

Displaying an updating path of a user’s location history](/documentation/MapKit/displaying-an-updating-path-of-a-user-s-location-history)

Continually update a MapKit overlay displaying the path a user travels.

[

Displaying Indoor Maps with MapKit JS](/documentation/MapKitJS/displaying-indoor-maps-with-mapkit-js)

Use the Indoor Mapping Data Format (IMDF) to show an indoor map with custom overlays and points of interest in your browser.

[

Displaying overlays on a map](/documentation/MapKit/displaying-overlays-on-a-map)

Add regions of layered content to a map view.

[

Explore a location with a highly detailed map and Look Around](/documentation/mapkit/mapkit_for_appkit_and_uikit/explore_a_location_with_a_highly_detailed_map_and_look_around)

Display a richly detailed map, and use Look Around to experience an interactive view of landmarks.

[

Finding devices with precision](/documentation/NearbyInteraction/finding-devices-with-precision)

Leverage the spatial awareness of ARKit and Apple Ultra Wideband Chips in your app to guide users to a nearby device.

[

Implementing Interactions Between Users in Close Proximity](/documentation/NearbyInteraction/implementing-interactions-between-users-in-close-proximity)

Enable devices to access relative positioning information.

[

Implementing proximity-based interactions between a phone and watch](/documentation/NearbyInteraction/implementing-proximity-based-interactions-between-a-phone-and-watch)

Interact with a nearby Apple Watch by measuring its distance to a paired iPhone.

[

Implementing spatial interactions with third-party accessories](/documentation/NearbyInteraction/implementing-spatial-interactions-with-third-party-accessories)

Establish a connection with a nearby accessory to receive periodic measurements of its distance from the user.

[

Interacting with nearby points of interest](/documentation/MapKit/interacting-with-nearby-points-of-interest)

Provide automatic search completions for a partial search query, search the map for relevant locations nearby, and retrieve details for selected points of interest.

[

Monitoring location changes with Core Location](/documentation/CoreLocation/monitoring-location-changes-with-core-location)

Define boundaries and act on user location updates.

[

Optimizing Map Views with Filtering and Camera Constraints](/documentation/mapkit/mkmapview/optimizing_map_views_with_filtering_and_camera_constraints)

Display a map that is relevant to the user by filtering points of interest and search results, and constraining the visible region.

[

Ranging for Beacons](/documentation/CoreLocation/ranging-for-beacons)

Configure a device to act as a beacon and to detect surrounding beacons.

[

Sharing Your Location to Find a Park](/documentation/CoreLocationUI/sharing-your-location-to-find-a-park)

Ask for location access using a customizable location button.

### [Metal](/documentation/samplecode/#Metal)

[

Accelerating ray tracing and motion blur using Metal](/documentation/Metal/accelerating-ray-tracing-and-motion-blur-using-metal)

Generate ray-traced images with motion blur using GPU-based parallel processing.

[

Accelerating ray tracing using Metal](/documentation/Metal/accelerating-ray-tracing-using-metal)

Implement ray-traced rendering using GPU-based parallel processing.

[

Achieving smooth frame rates with Metal’s display link](/documentation/Metal/achieving-smooth-frame-rates-with-metal-s-display-link)

Pace rendering with minimal input latency while providing essential information to the operating system for power-efficient rendering, thermal mitigation, and the scheduling of sustainable workloads.

[

Adding Custom Functions to a Shader Graph](/documentation/metalperformanceshadersgraph/adding_custom_functions_to_a_shader_graph)

Run your own graph functions on the GPU by building the function programmatically.

[

Adjusting the level of detail using Metal mesh shaders](/documentation/Metal/adjusting-the-level-of-detail-using-metal-mesh-shaders)

Choose and render meshes with several levels of detail using object and mesh shaders.

[

Animating and Denoising a Raytraced Scene](/documentation/metalperformanceshaders/animating_and_denoising_a_raytraced_scene)

Support dynamic scenes and denoising by extending your ray tracer with Metal Performance Shaders.

[

Applying temporal antialiasing and upscaling using MetalFX](/documentation/MetalFX/applying-temporal-antialiasing-and-upscaling-using-metalfx)

Reduce render workloads while increasing image detail with MetalFX.

[

Calculating Primitive Visibility Using Depth Testing](/documentation/Metal/calculating-primitive-visibility-using-depth-testing)

Determine which pixels are visible in a scene by using a depth texture.

[

Capturing Metal Commands Programmatically](/documentation/Metal/capturing-metal-commands-programmatically)

Invoke Metal’s frame capture from your app, then save the resulting GPU trace to a file or view it in Xcode.

[

Control the Ray Tracing Process Using Intersection Queries](/documentation/Metal/control-the-ray-tracing-process-using-intersection-queries)

Explicitly enumerate a ray’s intersections with acceleration structures by creating an intersection query object.

[

Creating a 3D application with Hydra rendering](/documentation/Metal/creating-a-3d-application-with-hydra-rendering)

Build a 3D application that integrates with Hydra and USD.

[

Creating a Custom Metal View](/documentation/Metal/creating-a-custom-metal-view)

Implement a lightweight view for Metal rendering that’s customized to your app’s needs.

[

Creating a Metal Dynamic Library](/documentation/Metal/creating-a-metal-dynamic-library)

Compile a library of shaders and write it to a file as a dynamically linked library.

[

Creating and Sampling Textures](/documentation/Metal/creating-and-sampling-textures)

Load image data into a texture and apply it to a quadrangle.

[

Culling occluded geometry using the visibility result buffer](/documentation/Metal/culling-occluded-geometry-using-the-visibility-result-buffer)

Draw a scene without rendering hidden geometry by checking whether each object in the scene is visible.

[

Customizing a PyTorch operation](/documentation/Metal/customizing-a-pytorch-operation)

Implement a custom operation in PyTorch that uses Metal kernels to improve performance.

[

Customizing a TensorFlow operation](/documentation/Metal/customizing-a-tensorflow-operation)

Implement a custom operation that uses Metal kernels to accelerate neural-network training performance.

[

Customizing Render Pass Setup](/documentation/Metal/customizing-render-pass-setup)

Render into an offscreen texture by creating a custom render pass.

[

Customizing shaders using function pointers and stitching](/documentation/Metal/customizing-shaders-using-function-pointers-and-stitching)

Define custom shader behavior at runtime by creating functions from existing ones and preferentially linking to others in a dynamic library.

[

Encoding Argument Buffers on the GPU](/documentation/Metal/encoding-argument-buffers-on-the-gpu)

Use a compute pass to encode an argument buffer and access its arguments in a subsequent render pass.

[

Encoding Indirect Command Buffers on the CPU](/documentation/Metal/encoding-indirect-command-buffers-on-the-cpu)

Reduce CPU overhead and simplify your command execution by reusing commands.

[

Encoding Indirect Command Buffers on the GPU](/documentation/Metal/encoding-indirect-command-buffers-on-the-gpu)

Maximize CPU to GPU parallelization by generating render commands on the GPU.

[

Filtering Images with MPSGraph FFT Operations](/documentation/metalperformanceshadersgraph/filtering_images_with_mpsgraph_fft_operations)

Filter an image with MPSGraph fast Fourier transforms using the convolutional theorem.

[

Implementing a Multistage Image Filter Using Heaps and Events](/documentation/Metal/implementing-a-multistage-image-filter-using-heaps-and-events)

Use events to synchronize access to resources allocated on a heap.

[

Implementing a Multistage Image Filter Using Heaps and Fences](/documentation/Metal/implementing-a-multistage-image-filter-using-heaps-and-fences)

Use fences to synchronize access to resources allocated on a heap.

[

Implementing Order-Independent Transparency with Image Blocks](/documentation/Metal/implementing-order-independent-transparency-with-image-blocks)

Draw overlapping, transparent surfaces in any order by using tile shaders and image blocks.

[

Improving edge-rendering quality with multisample antialiasing (MSAA)](/documentation/Metal/improving-edge-rendering-quality-with-multisample-antialiasing-msaa)

Use Metal’s MSAA to enhance the rendering of edges with custom resolve options and immediate and tile-based resolve paths.

[

Loading textures and models using Metal fast resource loading](/documentation/Metal/loading-textures-and-models-using-metal-fast-resource-loading)

Stream texture and buffer data directly from disk into Metal resources using fast resource loading.

[

Managing groups of resources with argument buffers](/documentation/Metal/managing-groups-of-resources-with-argument-buffers)

Create argument buffers to organize related resources.

[

Migrating OpenGL Code to Metal](/documentation/Metal/migrating-opengl-code-to-metal)

Replace your app’s deprecated OpenGL code with Metal.

[

Mixing Metal and OpenGL Rendering in a View](/documentation/Metal/mixing-metal-and-opengl-rendering-in-a-view)

Draw with Metal and OpenGL in the same view using an interoperable texture.

[

Modern Rendering with Metal](/documentation/Metal/modern-rendering-with-metal)

Use advanced Metal features such as indirect command buffers, sparse textures, and variable rate rasterization to implement complex rendering techniques.

[

Performing Calculations on a GPU](/documentation/Metal/performing-calculations-on-a-gpu)

Use Metal to find GPUs and perform calculations on them.

[

Processing a texture in a compute function](/documentation/Metal/processing-a-texture-in-a-compute-function)

Create textures by running copy and dispatch commands in a compute pass on a GPU.

Beta

[

Processing HDR Images with Metal](/documentation/Metal/processing-hdr-images-with-metal)

Implement a post-processing pipeline using the latest features on Apple GPUs.

[

Reading Pixel Data from a Drawable Texture](/documentation/Metal/reading-pixel-data-from-a-drawable-texture)

Access texture data from the CPU by copying it to a buffer.

[

Rendering a curve primitive in a ray tracing scene](/documentation/Metal/rendering-a-curve-primitive-in-a-ray-tracing-scene)

Implement ray traced rendering using GPU-based parallel processing.

[

Rendering a Scene with Deferred Lighting in C++](/documentation/Metal/rendering-a-scene-with-deferred-lighting-in-c++)

Avoid expensive lighting calculations by implementing a deferred lighting renderer optimized for immediate mode and tile-based deferred renderer GPUs.

[

Rendering a Scene with Deferred Lighting in Objective-C](/documentation/Metal/rendering-a-scene-with-deferred-lighting-in-objective-c)

Avoid expensive lighting calculations by implementing a deferred lighting renderer optimized for immediate mode and tile-based deferred renderer GPUs.

[

Rendering a Scene with Deferred Lighting in Swift](/documentation/Metal/rendering-a-scene-with-deferred-lighting-in-swift)

Avoid expensive lighting calculations by implementing a deferred lighting renderer optimized for immediate mode and tile-based deferred renderer GPUs.

[

Rendering a Scene with Forward Plus Lighting Using Tile Shaders](/documentation/Metal/rendering-a-scene-with-forward-plus-lighting-using-tile-shaders)

Implement a forward plus renderer using the latest features on Apple GPUs.

[

Rendering reflections in real time using ray tracing](/documentation/Metal/rendering-reflections-in-real-time-using-ray-tracing)

Implement realistic real-time lighting by dynamically generating reflection maps by encoding a ray-tracing compute pass.

[

Rendering Reflections with Fewer Render Passes](/documentation/Metal/rendering-reflections-with-fewer-render-passes)

Use layer selection to reduce the number of render passes needed to generate an environment map.

[

Rendering Terrain Dynamically with Argument Buffers](/documentation/Metal/rendering-terrain-dynamically-with-argument-buffers)

Use argument buffers to render terrain in real time with a GPU-driven pipeline.

[

Selecting Device Objects for Compute Processing](/documentation/Metal/selecting-device-objects-for-compute-processing)

Switch dynamically between multiple GPUs to efficiently execute a compute-intensive simulation.

[

Selecting Device Objects for Graphics Rendering](/documentation/Metal/selecting-device-objects-for-graphics-rendering)

Switch dynamically between multiple GPUs to efficiently render to a display.

[

Streaming large images with Metal sparse textures](/documentation/Metal/streaming-large-images-with-metal-sparse-textures)

Limit texture memory usage for large textures by loading or unloading image detail on the basis of MIP and tile region.

[

Supporting Simulator in a Metal app](/documentation/Metal/supporting-simulator-in-a-metal-app)

Configure alternative render paths in your Metal app to enable running your app in Simulator.

[

Synchronizing CPU and GPU Work](/documentation/Metal/synchronizing-cpu-and-gpu-work)

Avoid stalls between CPU and GPU work by using multiple instances of a resource.

[

Training a Neural Network using MPS Graph](/documentation/metalperformanceshadersgraph/training_a_neural_network_using_mps_graph)

Train a simple neural network digit classifier.

[

Training a Neural Network with Metal Performance Shaders](/documentation/metalperformanceshaders/training_a_neural_network_with_metal_performance_shaders)

Use an MPS neural network graph to train a simple neural network digit classifier.

[

Using a Render Pipeline to Render Primitives](/documentation/Metal/using-a-render-pipeline-to-render-primitives)

Render a colorful, 2D triangle by running a draw command on the GPU.

[

Using Argument Buffers with Resource Heaps](/documentation/Metal/using-argument-buffers-with-resource-heaps)

Reduce CPU overhead by using arrays inside argument buffers and combining them with resource heaps.

[

Using Function Specialization to Build Pipeline Variants](/documentation/Metal/using-function-specialization-to-build-pipeline-variants)

Create pipelines for different levels of detail from a common shader source.

[

Using Metal to Draw a View’s Contents](/documentation/Metal/using-metal-to-draw-a-view's-contents)

Create a MetalKit view and a render pass to draw the view’s contents.

### [Photos and video](/documentation/samplecode/#Photos-and-video)

[

Bringing Photos picker to your SwiftUI app](/documentation/PhotoKit/bringing-photos-picker-to-your-swiftui-app)

Select media assets by using a Photos picker view that SwiftUI provides.

[

Browsing and Modifying Photo Albums](/documentation/PhotoKit/browsing-and-modifying-photo-albums)

Help users organize their photos into albums and browse photo collections in a grid-based layout using PhotoKit.

[

Building a guessing game for visionOS](/documentation/GroupActivities/building-a-guessing-game-for-visionos)

Create a team-based guessing game for visionOS using Group Activities.

[

Capturing screen content in macOS](/documentation/ScreenCaptureKit/capturing-screen-content-in-macos)

Stream desktop content like displays, apps, and windows by adopting screen capture in your app.

[

Controlling a DockKit accessory using your camera app](/documentation/DockKit/controlling-a-dockkit-accessory-using-your-camera-app)

Follow subjects in real time using an iPhone that you mount on a DockKit accessory.

[

Creating a Slideshow Project Extension for Photos](/documentation/PhotoKit/creating-a-slideshow-project-extension-for-photos)

Augment the macOS Photos app with extensions that support project creation.

[

Drawing content in a group session](/documentation/groupactivities/drawing_content_in_a_group_session)

Invite your friends to draw on a shared canvas while on a FaceTime call.

[

Encoding video for live streaming](/documentation/VideoToolbox/encoding-video-for-live-streaming)

Configure a compression session to encode video for live streaming.

Beta

[

Encoding video for low-latency conferencing](/documentation/VideoToolbox/encoding-video-for-low-latency-conferencing)

Configure a compression session to optimize encoding for video-conferencing apps.

Beta

[

Encoding video for offline transcoding](/documentation/VideoToolbox/encoding-video-for-offline-transcoding)

Configure a compression session to transcode video in offline workflows.

Beta

[

Implementing an inline Photos picker](/documentation/PhotoKit/implementing-an-inline-photos-picker)

Embed a system-provided, half-height Photos picker into your app’s view.

[

Playing and editing Cinematic mode video](/documentation/Cinematic/playing-and-editing-cinematic-mode-video)

Play and edit Cinematic mode video with an adjustable depth of field and focus points.

[

Recording and Streaming Your macOS App](/documentation/ReplayKit/recording-and-streaming-your-macos-app)

Share screen recordings, or broadcast live audio and video of your app, by adding ReplayKit to your macOS apps and games.

[

Selecting Photos and Videos in iOS](/documentation/PhotoKit/selecting-photos-and-videos-in-ios)

Improve the user experience of finding and selecting assets by using the Photos picker.

### [RealityKit and Reality Composer Pro](/documentation/samplecode/#RealityKit-and-Reality-Composer-Pro)

[

Altering RealityKit Rendering with Shader Functions](/documentation/realitykit/altering_realitykit_rendering_with_shader_functions)

Create rendering effects by writing surface shaders and geometry modifiers.

[

Animating entity rotation with a system](/documentation/RealityKit/animated-rotation-with-a-system)

Rotate an entity around an axis using a Component and a System.

[

Building an Immersive Experience with RealityKit](/documentation/realitykit/building_an_immersive_experience_with_realitykit)

Use systems and postprocessing effects to create a realistic underwater scene.

[

Building an object reconstruction app](/documentation/RealityKit/building-an-object-reconstruction-app)

Reconstruct objects from user-selected input images by using photogrammetry.

[

Combining 2D and 3D views in an immersive app](/documentation/RealityKit/combining-2d-and-3d-views-in-an-immersive-app)

Use attachments to place 2D content relative to 3D content in your visionOS app.

[

Composing interactive 3D content with RealityKit and Reality Composer Pro](/documentation/RealityKit/composing-interactive-3d-content-with-realitykit-and-reality-composer-pro)

Build an interactive scene using an animation timeline.

[

Configuring Collision in RealityKit](/documentation/RealityKit/configuring-collision-in-realitykit)

Use collision groups and collision filters to control which objects collide.

[

Construct an immersive environment for visionOS](/documentation/RealityKit/construct-an-immersive-environment-for-visionOS)

Build efficient custom worlds for your app.

[

Controlling Entity Collisions in RealityKit](/documentation/realitykit/controlling_entity_collisions_in_realitykit)

Create collision filters to control which objects collide.

[

Creating a game with scene understanding](/documentation/realitykit/creating_a_game_with_scene_understanding)

Create AR games and experiences that interact with real-world objects on LiDAR-equipped iOS devices.

[

Creating an App for Face-Painting in AR](/documentation/RealityKit/creating-an-app-for-face-painting-in-ar)

Combine RealityKit’s face detection with PencilKit to implement virtual face-painting.

[

Creating a Photogrammetry Command-Line App](/documentation/realitykit/creating_a_photogrammetry_command-line_app)

Generate 3D objects from images using RealityKit Object Capture.

[

Creating a Spaceship game](/documentation/RealityKit/creating-a-spaceship-game)

Build an immersive game using RealityKit audio, simulation, and rendering features.

[

Creating a spatial drawing app with RealityKit](/documentation/RealityKit/creating-a-spatial-drawing-app-with-realitykit)

Use low-level mesh and texture APIs to achieve fast updates to a person’s brush strokes by integrating RealityKit with ARKit and SwiftUI.

[

Docking a video player in an immersive scene](/documentation/RealityKit/docking-a-video-player-in-an-immersive-scene)

Secure a video player in an immersive scene with a docking region you can specify.

[

Generating interactive geometry with RealityKit](/documentation/RealityKit/generating-interactive-geometry-with-realitykit)

Create an interactive mesh with low-level mesh and low-level texture.

[

Implementing Special Rendering Effects with RealityKit Postprocessing](/documentation/realitykit/implementing_special_rendering_effects_with_realitykit_postprocessing)

Implement a variety of postprocessing techniques to alter RealityKit rendering.

[

Presenting an artist’s scene](/documentation/RealityKit/presenting-an-artists-scene)

Display a scene from Reality Composer Pro in visionOS.

[

Rendering a windowed game in stereo](/documentation/RealityKit/rendering-a-windowed-game-in-stereo)

Bring an iOS or iPadOS game to visionOS and enhance it.

[

Responding to gestures on an entity](/documentation/RealityKit/responding-to-gestures-on-an-entity)

Respond to gestures performed on RealityKit entities using input target and collision components.

[

Scanning objects using Object Capture](/documentation/RealityKit/scanning-objects-using-object-capture)

Implement a full scanning workflow for capturing objects on iOS devices.

[

Schema definitions for third-party DCCs](/documentation/RealityKit/schema-definitions-for-third-party-dccs)

Update your local USD library to add interactive and augmented reality features.

[

Simulating particles in your visionOS app](/documentation/RealityKit/simulating-particles-in-your-visionos-app)

Add a range of visual effects to a RealityKit view by attaching a particle emitter component to an entity.

[

Simulating physics joints in your RealityKit app](/documentation/RealityKit/simulating-physics-joints-in-your-realitykit-app)

Create realistic, connected motion using physics joints.

[

Simulating physics with collisions in your visionOS app](/documentation/RealityKit/simulating-physics-with-collisions-in-your-visionos-app)

Create entities that behave and react like physical objects in a RealityKit view.

[

Taking Pictures for 3D Object Capture](/documentation/realitykit/taking_pictures_for_3d_object_capture)

Capture high-quality images with depth and gravity data to use with RealityKit Object Capture.

[

Transforming entities between RealityKit coordinate spaces](/documentation/RealityKit/transforming-entities-between-realitykit-coordinate-spaces)

Move an entity between a volumetric window and an immersive space using coordinate space transformations.

[

Transforming RealityKit entities using gestures](/documentation/RealityKit/transforming-realitykit-entities-with-gestures)

Build a RealityKit component to support standard visionOS gestures on any entity.

[

Using object capture assets in RealityKit](/documentation/realitykit/using_object_capture_assets_in_realitykit)

Create a chess game using RealityKit and assets created using Object Capture.

[

WWDC21 Challenge: Framework Freestyle](/documentation/realitykit/wwdc21_challenge_framework_freestyle)

An AR experience that randomly selects a programming framework and maps it onto the user’s face.

### [StoreKit](/documentation/samplecode/#StoreKit)

[

Determining service entitlement on the server](/documentation/StoreKit/determining-service-entitlement-on-the-server)

Identify a customer’s entitlement to your service, offers, and messaging by analyzing a validated receipt and the state of their subscription.

[

Generating a Promotional Offer Signature on the Server](/documentation/StoreKit/generating-a-promotional-offer-signature-on-the-server)

Generate a signature using your private key and lightweight cryptography libraries.

[

Implementing a store in your app using the StoreKit API](/documentation/StoreKit/implementing-a-store-in-your-app-using-the-storekit-api)

Offer In-App Purchases and manage entitlements using signed transactions and status information.

[

Offering, completing, and restoring in-app purchases](/documentation/StoreKit/offering-completing-and-restoring-in-app-purchases)

Fetch, display, purchase, validate, and finish transactions in your app.

[

Offering media for sale in your app](/documentation/StoreKit/offering-media-for-sale-in-your-app)

Allow users to purchase media in the App Store from within your app.

[

Requesting App Store reviews](/documentation/StoreKit/requesting-app-store-reviews)

Implement best practices for prompting users to review your app in the App Store.

[

Testing and validating ad impression signatures and postbacks for SKAdNetwork](/documentation/StoreKitTest/testing-and-validating-ad-impression-signatures-and-postbacks-for-skadnetwork)

Validate your ad impressions and test your postbacks by creating unit tests using the StoreKit Test framework.

### [Swift and SwiftData](/documentation/samplecode/#Swift-and-SwiftData)

[

Adding and editing persistent data in your app](/documentation/SwiftData/Adding-and-editing-persistent-data-in-your-app)

Create a data entry form for collecting and changing data managed by SwiftData.

[

Calling APIs Across Language Boundaries](/documentation/Swift/CallingAPIsAcrossLanguageBoundaries)

Use a variety of C++ APIs in Swift – and vice-versa – across multiple targets and frameworks in an Xcode project.

[

Defining data relationships with enumerations and model classes](/documentation/SwiftData/Defining-data-relationships-with-enumerations-and-model-classes)

Create relationships for static and dynamic data stored in your app.

[

Deleting persistent data from your app](/documentation/SwiftData/Deleting-persistent-data-from-your-app)

Explore different ways to use SwiftData to delete persistent data.

[

Filtering and sorting persistent data](/documentation/SwiftData/Filtering-and-sorting-persistent-data)

Manage data store presentation using predicates and dynamic queries.

[

Maintaining a local copy of server data](/documentation/SwiftData/Maintaining-a-local-copy-of-server-data)

Create and update a persistent store to cache read-only network data.

[

Mixing Languages in an Xcode project](/documentation/Swift/MixingLanguagesInAnXcodeProject)

Use C++ APIs in Swift – and Swift APIs in C++ – in a single framework target, and consume the framework’s APIs in a separate app target.

[

TicTacFish: Implementing a game using distributed actors](/documentation/swift/tictacfish_implementing_a_game_using_distributed_actors)

Use distributed actors to take your Swift concurrency and actor-based apps beyond a single process.

[

Updating an app to use strict concurrency](/documentation/Swift/updating-an-app-to-use-strict-concurrency)

Use this code to follow along with a guide to migrating your code to take advantage of the full concurrency protection that the Swift 6 language mode provides.

[

Updating an App to Use Swift Concurrency](/documentation/swift/updating_an_app_to_use_swift_concurrency)

Improve your app’s performance by refactoring your code to take advantage of asynchronous functions in Swift.

### [SwiftUI](/documentation/samplecode/#SwiftUI)

[

Add Rich Graphics to Your SwiftUI App](/documentation/swiftui/add_rich_graphics_to_your_swiftui_app)

Make your apps stand out by adding background materials, vibrancy, custom graphics, and animations.

[

Adopting drag and drop using SwiftUI](/documentation/SwiftUI/Adopting-drag-and-drop-using-SwiftUI)

Enable drag-and-drop interactions in lists, tables and custom views.

[

Backyard Birds: Building an app with SwiftData and widgets](/documentation/SwiftUI/Backyard-birds-sample)

Create an app with persistent data, interactive widgets, and an all new in-app purchase experience.

[

Bringing multiple windows to your SwiftUI app](/documentation/swiftui/bringing_multiple_windows_to_your_swiftui_app)

Compose rich views by reacting to state changes and customize your app’s scene presentation and behavior on iPadOS and macOS.

[

Bringing robust navigation structure to your SwiftUI app](/documentation/SwiftUI/Bringing-robust-navigation-structure-to-your-swiftui-app)

Use navigation links, stacks, destinations, and paths to provide a streamlined experience for all platforms, as well as behaviors such as deep linking and state restoration.

[

Building a document-based app using SwiftData](/documentation/SwiftUI/Building-a-document-based-app-using-SwiftData)

Code along with the WWDC presenter to transform an app with SwiftData.

[

Building a Great Mac App with SwiftUI](/documentation/swiftui/building_a_great_mac_app_with_swiftui)

Create engaging SwiftUI Mac apps by incorporating side bars, tables, toolbars, and several other popular user interface elements.

[

Building custom views in SwiftUI](/documentation/swiftui/building_custom_views_in_swiftui)

Create a custom view with data-driven transitions and animations in SwiftUI.

[

Composing custom layouts with SwiftUI](/documentation/swiftui/composing_custom_layouts_with_swiftui)

Arrange views in your app’s interface using layout tools that SwiftUI provides.

[

Controlling the timing and movements of your animations](/documentation/SwiftUI/Controlling-the-timing-and-movements-of-your-animations)

Build sophisticated animations that you control using phase and keyframe animators.

[

Creating Accessible Views](/documentation/swiftui/creating_accessible_views)

Make your app accessible to everyone by applying accessibility modifiers to your SwiftUI views.

[

Creating a tvOS media catalog app in SwiftUI](/documentation/SwiftUI/Creating-a-tvOS-media-catalog-app-in-SwiftUI)

Build standard content lockups and rows of content shelves for your tvOS app.

[

Creating custom container views](/documentation/SwiftUI/Creating-custom-container-views)

Access individual subviews to compose flexible container views.

[

Creating visual effects with SwiftUI](/documentation/SwiftUI/Creating-visual-effects-with-SwiftUI)

Add scroll effects, rich color treatments, custom transitions, and advanced effects using shaders and a text renderer.

[

Customizing window styles and state-restoration behavior in macOS](/documentation/SwiftUI/Customizing-window-styles-and-state-restoration-behavior-in-macOS)

Configure how your app’s windows look and function in macOS to provide an engaging and more coherent experience.

[

Enhancing your app’s content with tab navigation](/documentation/SwiftUI/Enhancing-your-app-content-with-tab-navigation)

Keep your app content front and center while providing quick access to navigation using the tab bar.

[

Focus Cookbook: Supporting and enhancing focus-driven interactions in your SwiftUI app](/documentation/SwiftUI/Focus-Cookbook-sample)

Create custom focusable views with key-press handlers that accelerate keyboard input and support movement, and control focus programmatically.

[

Food Truck: Building a SwiftUI multiplatform app](/documentation/swiftui/food_truck_building_a_swiftui_multiplatform_app)

Create a single codebase and app target for Mac, iPad, and iPhone.

[

Fruta: Building a Feature-Rich App with SwiftUI](/documentation/appclip/fruta_building_a_feature-rich_app_with_swiftui)

Create a shared codebase to build a multiplatform app that offers widgets and an App Clip.

[

Loading and Displaying a Large Data Feed](/documentation/swiftui/loading_and_displaying_a_large_data_feed)

Consume data in the background, and lower memory use by batching imports and preventing duplicate records.

[

Managing model data in your app](/documentation/SwiftUI/Managing-model-data-in-your-app)

Create connections between your app’s data model and views.

[

Migrating from the Observable Object protocol to the Observable macro](/documentation/SwiftUI/Migrating-from-the-observable-object-protocol-to-the-observable-macro)

Update your existing app to leverage the benefits of Observation in Swift.

[

Monitoring data changes in your app](/documentation/SwiftUI/Monitoring-model-data-changes-in-your-app)

Show changes to data in your app’s user interface by using observable objects.

[

Restoring Your App’s State with SwiftUI](/documentation/swiftui/restoring_your_app_s_state_with_swiftui)

Provide app continuity for users by preserving their current activities.

### [System](/documentation/samplecode/#System)

[

Authorizing a Bluetooth accessory to share a dice roll](/documentation/accessorysetupkit/authorizing-a-bluetooth-accessory-to-share-a-dice-roll)

Discover, select, and set up a specific Bluetooth accessory without requesting permission to use Bluetooth.

[

Building a custom peer-to-peer protocol](/documentation/Network/building-a-custom-peer-to-peer-protocol)

Use networking frameworks to create a custom protocol for playing a game across iOS, iPadOS, watchOS, and tvOS devices.

[

Building an NFC Tag-Reader App](/documentation/CoreNFC/building-an-nfc-tag-reader-app)

Read NFC tags with NDEF messages in your app.

[

Building a Simple USB Driver](/documentation/kernel/hardware_families/usb/building_a_simple_usb_driver)

Set up and load a driver that logs output to the Console app.

[

Collecting Network Connection Metrics](/documentation/Network/collecting-network-connection-metrics)

Use reports to understand how DNS and protocol handshakes impact connection establishment.

[

Communicating between a DriverKit extension and a client app](/documentation/DriverKit/communicating-between-a-driverkit-extension-and-a-client-app)

Send and receive different kinds of data securely by validating inputs and asynchronously by storing and using a callback.

[

Communicating with a Modem on a Serial Port](/documentation/iokit/communicating_with_a_modem_on_a_serial_port)

Find and connect to a modem attached to a serial port using IOKit.

[

Compressing and decompressing files with stream compression](/documentation/accelerate/compressing_and_decompressing_files_with_stream_compression)

Perform compression for all files and decompression for files with supported extension types.

[

Configuring a Wi-Fi accessory to join a network](/documentation/NetworkExtension/configuring-a-wi-fi-accessory-to-join-a-network)

Associate an iOS device with an accessory’s network to deliver network configuration information.

[

Connecting a network driver](/documentation/pcidriverkit/connecting_a_network_driver)

Create an Ethernet driver that interfaces with the system’s network protocol stack.

[

Constraining a tool’s launch environment](/documentation/Security/constraining-a-tool's-launch-environment)

Improve the security of your macOS app by limiting the ways its components can run.

[

Creating a MIDI device driver](/documentation/MIDIDriverKit/creating-a-midi-device-driver)

Implement a configurable virtual MIDI driver as a driver extension that runs in user space in macOS and iPadOS.

[

Creating NFC Tags from Your iPhone](/documentation/CoreNFC/creating-nfc-tags-from-your-iphone)

Save data to tags, and interact with them using native tag protocols.

[

Encrypting and Decrypting a Single File](/documentation/AppleArchive/encrypting-and-decrypting-a-single-file)

Encrypt a single file and save the result to the file system, then decrypt and recreate the original file from the archive file using Apple Encrypted Archive.

[

Encrypting and Decrypting a String](/documentation/AppleArchive/encrypting-and-decrypting-a-string)

Encrypt the contents of a string and save the result to the file system, then decrypt and recreate the string from the archive file using Apple Encrypted Archive.

[

Encrypting and Decrypting Directories](/documentation/AppleArchive/encrypting-and-decrypting-directories)

Compress and encrypt the contents of an entire directory or decompress and decrypt an archived directory using Apple Encrypted Archive.

[

Filtering Network Traffic](/documentation/NetworkExtension/filtering-network-traffic)

Use the Network Extension framework to allow or deny network connections.

[

Handling Keyboard Events from a Human Interface Device](/documentation/HIDDriverKit/handling-keyboard-events-from-a-human-interface-device)

Process keyboard-related data from a human interface device and dispatch events to the system.

[

Handling Stylus Input from a Human Interface Device](/documentation/HIDDriverKit/handling-stylus-input-from-a-human-interface-device)

Process stylus-related input from a human interface device and dispatch events to the system.

[

Implementing netcat with Network Framework](/documentation/Network/implementing-netcat-with-network-framework)

Build a simple \`netcat\` tool that establishes network connections and transfers data.

[

Monitoring System Events with Endpoint Security](/documentation/EndpointSecurity/monitoring-system-events-with-endpoint-security)

Receive notifications and authorization requests for sensitive operations by creating an Endpoint Security client for your app.

[

Performing Common Cryptographic Operations](/documentation/cryptokit/performing_common_cryptographic_operations)

Use CryptoKit to carry out operations like hashing, key generation, and encryption.

[

Receiving Voice and Text Communications on a Local Network](/documentation/NetworkExtension/receiving-voice-and-text-communications-on-a-local-network)

Provide voice and text communication on a local network isolated from Apple Push Notification service by adopting Local Push Connectivity.

[

Running GUI Linux in a virtual machine on a Mac](/documentation/Virtualization/running-gui-linux-in-a-virtual-machine-on-a-mac)

Install and run GUI Linux in a virtual machine using the Virtualization framework.

[

Running Linux in a Virtual Machine](/documentation/Virtualization/running-linux-in-a-virtual-machine)

Run a Linux operating system on your Mac using the Virtualization framework.

[

Running macOS in a virtual machine on Apple silicon](/documentation/Virtualization/running-macos-in-a-virtual-machine-on-apple-silicon)

Install and run macOS in a virtual machine using the Virtualization framework.

[

Setting up and authorizing a Bluetooth accessory](/documentation/AccessorySetupKit/setting-up-and-authorizing-a-bluetooth-accessory)

Discover, select, and set up a specific Bluetooth accessory without requesting permission to use Bluetooth.

[

Storing CryptoKit Keys in the Keychain](/documentation/cryptokit/storing_cryptokit_keys_in_the_keychain)

Convert between strongly typed cryptographic keys and native keychain types.

### [TV](/documentation/samplecode/#TV)

[

Adopting Picture in Picture Playback in tvOS](/documentation/AVKit/adopting-picture-in-picture-playback-in-tvos)

Add advanced multitasking capabilities to your video apps by using Picture in Picture playback in tvOS.

[

Binding JSON data to TVML documents](/documentation/tvmljs/binding_json_data_to_tvml_documents)

Create full-fledged TVML documents by using data binding and queries on simplified TVML files.

[

Building a Full Screen Top Shelf Extension](/documentation/TVServices/building-a-full-screen-top-shelf-extension)

Highlight content from your Apple TV application by building a full screen Top Shelf extension.

[

Creating a Client-Server TVML App](/documentation/tvmljs/creating_a_client-server_tvml_app)

Display and navigate between TVML documents on Apple TV by retrieving and parsing information from a remote server.

[

Creating a multiview video playback experience in visionOS](/documentation/AVKit/creating-a-multiview-video-playback-experience-in-visionos)

Build an interface that plays multiple videos simultaneously and handles transitions to different experience types gracefully.

[

Creating immersive experiences using a full-screen layout](/documentation/TVUIKit/creating-immersive-experiences-using-a-full-screen-layout)

Display content with a collection view that maximizes the tvOS experience.

[

Displaying a Product or Bundle in a Full-Page Template](/documentation/TVML/displaying-a-product-or-bundle-in-a-full-page-template)

Specify scrollable and fixed regions in a product page.

[

Implementing a Hybrid TV App with TVMLKit](/documentation/TVMLKit/implementing-a-hybrid-tv-app-with-tvmlkit)

Display content options with document view controllers and fetch and populate content with TVMLKit JS.

[

Mapping Apple TV users to app profiles](/documentation/TVServices/mapping-apple-tv-users-to-app-profiles)

Adapt the content of your app for the current viewer by using an entitlement and simplifying sign-in flows.

[

Playing Media in a Client-Server App](/documentation/tvmljs/playing_media_in_a_client-server_app)

Play media items in a client-server app using the built-in media player for TVMLKit JS.

[

Playing video content in a standard user interface](/documentation/AVKit/playing-video-content-in-a-standard-user-interface)

Play media full screen, embedded inline, or in a floating Picture in Picture (PiP) window using a player view controller.

[

Responding to User Interaction](/documentation/tvmljs/responding_to_user_interaction)

Update onscreen information by adding event listeners to your Apple TV app.

[

Supporting Continuity Camera in your tvOS app](/documentation/AVKit/supporting-continuity-camera-in-your-tvos-app)

Capture high-quality photos, video, and audio in your Apple TV app by connecting an iPhone or iPad as a continuity device.

[

Supporting Multiple Users in Your tvOS App](/documentation/TVServices/supporting-multiple-users-in-your-tvos-app)

Store separate data for each user with the new Runs as Current User capability.

[

Working with Overlays and Parental Controls in tvOS](/documentation/AVKit/working-with-overlays-and-parental-controls-in-tvos)

Add interactive overlays, parental controls, and livestream channel flipping using a player view controller.

### [UIKit](/documentation/samplecode/#UIKit)

[

Add Home Screen quick actions](/documentation/UIKit/add-home-screen-quick-actions)

Expose commonly used functionality with static or dynamic 3D Touch Home Screen quick actions.

[

Adding context menus in your app](/documentation/UIKit/adding-context-menus-in-your-app)

Provide quick access to useful actions by adding context menus to your iOS app.

[

Adding hardware keyboard support to your app](/documentation/UIKit/adding-hardware-keyboard-support-to-your-app)

Enhance interactions with your app by handling raw keyboard events, writing custom keyboard shortcuts, and working with gesture recognizers.

[

Adding menus and shortcuts to the menu bar and user interface](/documentation/UIKit/adding-menus-and-shortcuts-to-the-menu-bar-and-user-interface)

Provide quick access to useful actions by adding menus and keyboard shortcuts to your Mac app built with Mac Catalyst.

[

Adjusting your layout with keyboard layout guide](/documentation/UIKit/adjusting-your-layout-with-keyboard-layout-guide)

Respond dynamically to keyboard movement by using the tracking features of the keyboard layout guide.

[

Adopting drag and drop in a custom view](/documentation/UIKit/adopting-drag-and-drop-in-a-custom-view)

Demonstrates how to enable drag and drop for a \`UIImageView\` instance.

[

Adopting drag and drop in a table view](/documentation/UIKit/adopting-drag-and-drop-in-a-table-view)

Demonstrates how to enable and implement drag and drop for a table view.

[

Adopting hover support for Apple Pencil](/documentation/UIKit/adopting-hover-support-for-apple-pencil)

Enhance user feedback for your iPadOS app with a hover preview for Apple Pencil input.

[

Adopting iOS Dark Mode](/documentation/UIKit/adopting-ios-dark-mode)

Adopt Dark Mode in your iOS app by using dynamic colors and visual effects.

[

Adopting menus and UIActions in your user interface](/documentation/UIKit/adopting-menus-and-uiactions-in-your-user-interface)

Add menus to your user interface, with built-in button support and bar-button items, and create custom menu experiences.

[

Asynchronously loading images into table and collection views](/documentation/UIKit/asynchronously-loading-images-into-table-and-collection-views)

Store and fetch images asynchronously to make your app more responsive.

[

Building a document browser app for custom file formats](/documentation/UIKit/building-a-document-browser-app-for-custom-file-formats)

Implement a custom document file format to manage user interactions with files on different cloud storage providers.

[

Building a document browser-based app](/documentation/UIKit/building-a-document-browser-based-app)

Use a document browser to provide access to the user’s text files.

[

Building and improving your app with Mac Catalyst](/documentation/UIKit/building-and-improving-your-app-with-mac-catalyst)

Improve your iPadOS app with Mac Catalyst by supporting native controls, multiple windows, sharing, printing, menus and keyboard shortcuts.

[

Building high-performance lists and collection views](/documentation/UIKit/building-high-performance-lists-and-collection-views)

Improve the performance of lists and collections in your app with prefetching and image preparation.

[

Changing the appearance of selected and highlighted cells](/documentation/UIKit/changing-the-appearance-of-selected-and-highlighted-cells)

Provide visual feedback to the user about the state of a cell and the transition between states.

[

Creating self-sizing table view cells](/documentation/UIKit/creating-self-sizing-table-view-cells)

Create table view cells that support Dynamic Type and use system spacing constraints to adjust the spacing surrounding text labels.

[

Customizing and resizing sheets in UIKit](/documentation/UIKit/customizing-and-resizing-sheets-in-uikit)

Discover how to create a layered and customized sheet experience in UIKit.

[

Customizing an image picker controller](/documentation/UIKit/customizing-an-image-picker-controller)

Manage user interactions and present custom information when taking pictures by adding an overlay view to your image picker.

[

Customizing collection view layouts](/documentation/UIKit/customizing-collection-view-layouts)

Customize a view layout by changing the size of cells in the flow or implementing a mosaic style.

[

Customizing your app’s navigation bar](/documentation/UIKit/customizing-your-app-s-navigation-bar)

Create custom titles, prompts, and buttons in your app’s navigation bar.

[

Data delivery with drag and drop](/documentation/UIKit/data-delivery-with-drag-and-drop)

Share data between iPad apps during a drag and drop operation using an item provider.

[

Detecting changes in the preferences window](/documentation/UIKit/detecting-changes-in-the-preferences-window)

Listen for and respond to a user’s preference changes in your Mac app built with Mac Catalyst using Combine.

[

Disabling the pull-down gesture for a sheet](/documentation/UIKit/disabling-the-pull-down-gesture-for-a-sheet)

Ensure a positive user experience when presenting a view controller as a sheet.

[

Displaying searchable content by using a search controller](/documentation/UIKit/displaying-searchable-content-by-using-a-search-controller)

Create a user interface with searchable content in a table view.

[

Display text with a custom layout](/documentation/UIKit/display-text-with-a-custom-layout)

Lay out text in a custom-shaped container and apply glyph substitutions.

[

Enhancing your iPad app with pointer interactions](/documentation/UIKit/enhancing-your-ipad-app-with-pointer-interactions)

Provide a great user experience with pointing devices, by incorporating pointer content effects and shape customizations.

[

Enriching your text in text views](/documentation/UIKit/enriching-your-text-in-text-views)

Add exclusion paths, text attachments, and text lists to your text, and render it with text views.

[

Illustrating the force, altitude, and azimuth properties of touch input](/documentation/UIKit/illustrating-the-force-altitude-and-azimuth-properties-of-touch-input)

Capture Apple Pencil and touch input in views.

[

Implementing modern collection views](/documentation/UIKit/implementing-modern-collection-views)

Bring compositional layouts to your app and simplify updating your user interface with diffable data sources.

[

Implementing Peek and Pop](/documentation/UIKit/implementing-peek-and-pop)

Accelerate actions in your app by providing shortcuts to preview content in detail view controllers.

[

Integrating pointer interactions into your iPad app](/documentation/UIKit/integrating-pointer-interactions-into-your-ipad-app)

Support touch interactions in your iPad app by adding pointer interactions to your views.

[

Leveraging touch input for drawing apps](/documentation/UIKit/leveraging-touch-input-for-drawing-apps)

Capture touches as a series of strokes and render them efficiently on a drawing canvas.

[

Navigating an app’s user interface using a keyboard](/documentation/UIKit/navigating-an-app-s-user-interface-using-a-keyboard)

Navigate between user interface elements using a keyboard and focusable UI elements in iPad apps and apps built with Mac Catalyst.

[

Prefetching collection view data](/documentation/UIKit/prefetching-collection-view-data)

Load data for collection view cells before they display.

[

Restoring your app’s state](/documentation/UIKit/restoring-your-app-s-state)

Provide continuity for the user by preserving current activities.

[

Restoring Your App’s State with SwiftUI](/documentation/swiftui/restoring_your_app_s_state_with_swiftui)

Provide app continuity for users by preserving their current activities.

[

Selecting multiple items with a two-finger pan gesture](/documentation/UIKit/selecting-multiple-items-with-a-two-finger-pan-gesture)

Accelerate user selection of multiple items using the multiselect gesture on table and collection views.

[

Showing help tags for views and controls using tooltip interactions](/documentation/UIKit/showing-help-tags-for-views-and-controls-using-tooltip-interactions)

Explain the purpose of interface elements by showing a tooltip when a person positions the pointer over the element.

[

Supporting desktop-class features in your iPad app](/documentation/UIKit/supporting-desktop-class-features-in-your-ipad-app)

Enhance your iPad app by adding desktop-class features and document support.

[

Supporting gesture interaction in your apps](/documentation/UIKit/supporting-gesture-interaction-in-your-apps)

Enrich your app’s user experience by supporting standard and custom gesture interaction.

[

Supporting HDR images in your app](/documentation/UIKit/supporting-hdr-images-in-your-app)

​ Load, display, edit, and save HDR images using SwiftUI and Core Image. ​

[

Supporting multiple windows on iPad](/documentation/UIKit/supporting-multiple-windows-on-ipad)

Support side-by-side instances of your app’s interface and create new windows.

[

Synchronizing documents in the iCloud environment](/documentation/UIKit/synchronizing-documents-in-the-icloud-environment)

Manage documents across multiple devices to create a seamless editing and collaboration experience.

[

UIKit Catalog: Creating and customizing views and controls](/documentation/UIKit/uikit-catalog-creating-and-customizing-views-and-controls)

Customize your app’s user interface with views and controls.

[

Updating collection views using diffable data sources](/documentation/UIKit/updating-collection-views-using-diffable-data-sources)

Streamline the display and update of data in a collection view using a diffable data source that contains identifiers.

[

Using suggested searches with a search controller](/documentation/UIKit/using-suggested-searches-with-a-search-controller)

Create a search interface with a table view of suggested searches.

[

Using SwiftUI with UIKit](/documentation/UIKit/using-swiftui-with-uikit)

Learn how to incorporate SwiftUI views into a UIKit app.

[

Using TextKit 2 to interact with text](/documentation/UIKit/using-textkit-2-to-interact-with-text)

Interact with text by managing text selection and inserting custom text elements.

### [Vision](/documentation/samplecode/#Vision)

[

Aligning Similar Images](/documentation/Vision/aligning-similar-images)

Construct a composite image from images that capture the same scene.

[

Analyzing a selfie and visualizing its content](/documentation/Vision/analyzing-a-selfie-and-visualizing-its-content)

Calculate face-capture quality and visualize facial features for a collection of images using the Vision framework.

[

Analyzing Image Similarity with Feature Print](/documentation/Vision/analyzing-image-similarity-with-feature-print)

Generate a feature print to compute distance between images.

[

Applying Matte Effects to People in Images and Video](/documentation/Vision/applying-matte-effects-to-people-in-images-and-video)

Generate image masks for people automatically by using semantic person-segmentation.

[

Applying visual effects to foreground subjects](/documentation/Vision/applying-visual-effects-to-foreground-subjects)

Segment the foreground subjects of an image and composite them to a new background with visual effects.

[

Building a feature-rich app for sports analysis](/documentation/Vision/building-a-feature-rich-app-for-sports-analysis)

Detect and classify human activity in real time using computer vision and machine learning.

[

Classifying images for categorization and search](/documentation/Vision/classifying-images-for-categorization-and-search)

Analyze and label images using a Vision classification request.

[

Detecting animal body poses with Vision](/documentation/Vision/detecting-animal-body-poses-with-vision)

Draw the skeleton of an animal by using Vision’s capability to detect animal body poses.

[

Detecting Hand Poses with Vision](/documentation/Vision/detecting-hand-poses-with-vision)

Create a virtual drawing app by using Vision’s capability to detect hand poses.

[

Detecting human body poses in 3D with Vision](/documentation/Vision/detecting-human-body-poses-in-3d-with-vision)

Render skeletons of 3D body pose points in a scene overlaying the input image.

[

Detecting moving objects in a video](/documentation/Vision/detecting-moving-objects-in-a-video)

Identify the trajectory of a thrown object by using Vision.

[

Detecting Objects in Still Images](/documentation/Vision/detecting-objects-in-still-images)

Locate and demarcate rectangles, faces, barcodes, and text in images using the Vision framework.

[

Extracting phone numbers from text in images](/documentation/Vision/extracting-phone-numbers-from-text-in-images)

Analyze and filter phone numbers from text in live capture by using Vision.

[

Generating high-quality thumbnails from videos](/documentation/Vision/generating-thumbnails-from-videos)

Identify the most visually pleasing frames in a video by using the image-aesthetics scores request.

[

Highlighting Areas of Interest in an Image Using Saliency](/documentation/Vision/highlighting-areas-of-interest-in-an-image-using-saliency)

Quantify and visualize where people are likely to look in an image.

[

Locating and displaying recognized text](/documentation/Vision/locating-and-displaying-recognized-text)

Perform text recognition on a photo using the Vision framework’s text-recognition request.

[

Recognizing Objects in Live Capture](/documentation/Vision/recognizing-objects-in-live-capture)

Apply Vision algorithms to identify objects in real-time video.

[

Segmenting and colorizing individuals from a surrounding scene](/documentation/Vision/segmenting-and-colorizing-individuals-from-a-surrounding-scene)

Use the Vision framework to isolate and apply colors to people in an image.

[

Selecting a selfie based on capture quality](/documentation/Vision/selecting-a-selfie-based-on-capture-quality)

Compare face-capture quality in a set of images by using Vision.

[

Structuring Recognized Text on a Document](/documentation/visionkit/structuring_recognized_text_on_a_document)

Detect, recognize, and structure text on a business card or receipt using Vision and VisionKit.

[

Tracking Multiple Objects or Rectangles in Video](/documentation/Vision/tracking-multiple-objects-or-rectangles-in-video)

Apply Vision algorithms to track objects or rectangles throughout a video.

[

Tracking the User’s Face in Real Time](/documentation/Vision/tracking-the-user-s-face-in-real-time)

Detect and track faces from the selfie cam feed in real time.

[

Training a Create ML Model to Classify Flowers](/documentation/Vision/training-a-create-ml-model-to-classify-flowers)

Train a flower classifier using Create ML in Swift Playgrounds, and apply the resulting model to real-time image classification using Vision.

### [visionOS](/documentation/samplecode/#visionOS)

[

Accessing the main camera](/documentation/visionOS/accessing-the-main-camera)

Add camera-based features to enterprise apps.

[

Adding a depth effect to text in visionOS](/documentation/visionOS/adding-a-depth-effect-to-text-in-visionOS)

Create text that expands out of a window using stacked SwiftUI text views.

[

Applying mesh to real-world surroundings](/documentation/visionOS/applying-mesh-to-real-world-surroundings)

Add a layer of mesh to objects in the real world, using scene reconstruction in ARKit.

[

BOT-anist](/documentation/visionOS/BOT-anist)

Build a multiplatform app that uses windows, volumes, and animations to create a robot botanist’s greenhouse.

[

Building an immersive media viewing experience](/documentation/visionOS/building-an-immersive-media-viewing-experience)

Add a deeper level of immersion to media playback in your app with RealityKit and Reality Composer Pro.

[

Building local experiences with room tracking](/documentation/visionOS/building_local_experiences_with_room_tracking)

Use room tracking in visionOS to provide custom interactions with physical spaces.

[

Creating 2D shapes with SwiftUI](/documentation/visionOS/creating-2d-shapes-in-visionos-with-swiftui)

Draw two-dimensional shapes in your visionOS app with SwiftUI shapes or with your custom shapes.

[

Creating 3D entities with RealityKit](/documentation/visionOS/creating-3d-shapes-in-visionos-with-realitykit)

Display a horizontal row of three-dimensional shapes in your visionOS app, using predefined mesh and white material.

[

Creating 3D models as movable windows](/documentation/visionOS/creating-a-volumetric-window-in-visionos)

Display 3D content with a volumetric window that people can move.

[

Creating a 3D painting space](/documentation/visionOS/creating-a-painting-space-in-visionos)

Implement a painting canvas entity, and update its mesh to represent a stroke.

[

Creating an immersive space in visionOS](/documentation/visionOS/creating-immersive-spaces-in-visionos-with-swiftui)

Enhance your visionOS app by adding an immersive space using RealityKit.

[

Creating an interactive 3D model in visionOS](/documentation/visionOS/creating-an-interactable-3d-model-in-visionos)

Display an interactive car model using gestures in a reality view.

[

Creating SwiftUI windows in visionOS](/documentation/visionOS/creating-a-new-swiftui-window-in-visionos)

Display and manage multiple SwiftUI windows in your visionOS app.

[

Destination Video](/documentation/visionOS/destination-video)

Leverage SwiftUI to build an immersive media experience in a multiplatform app.

[

Diorama](/documentation/visionOS/diorama)

Design scenes for your visionOS app using Reality Composer Pro.

[

Displaying a 3D environment through a portal](/documentation/visionOS/displaying-a-3D-environment-through-a-portal)

Implement a portal window that displays a 3D environment and simulates entering a portal by using RealityKit.

[

Displaying an entity that follows a person’s view](/documentation/visionOS/displaying-a-3D-object-that-moves-to-stay-in-a-person's-view)

Create an entity that tracks and follows head movement in an immersive scene.

[

Displaying a stereoscopic image](/documentation/visionOS/displaying-a-stereoscopic-image-in-visionos)

Build a stereoscopic image by applying textures to the left and right eye in a shader graph material.

[

Displaying text in visionOS](/documentation/visionOS/displaying-text-in-visionOS)

Create styled text in a window using SwiftUI.

[

Displaying video from connected devices](/documentation/visionOS/displaying-video-from-connected-devices)

Show video from devices connected with the Developer Strap in your visionOS app.

[

Enabling video reflections in an immersive environment](/documentation/visionOS/enabling-video-reflections-in-an-immersive-environment)

Create a more immersive experience by adding video reflections in a custom environment.

[

Exploring object tracking with ARKit](/documentation/visionOS/exploring_object_tracking_with_arkit)

Find and track real-world objects in visionOS using reference objects trained with Create ML.

[

Generating procedural textures](/documentation/visionOS/generating-procedural-textures-in-visionos)

Display a 3D model that generates procedural textures in a reality view.

[

Happy Beam](/documentation/visionOS/happybeam)

Leverage a Full Space to create a fun game using ARKit.

[

Hello World](/documentation/visionOS/World)

Use windows, volumes, and immersive spaces to teach people about the Earth.

[

Implementing adjustable material](/documentation/visionOS/implementing-adjustable-material-in-visionos)

Update the adjustable parameters of a 3D model in visionOS.

[

Incorporating real-world surroundings in an immersive experience](/documentation/visionOS/incorporating-real-world-surroundings-in-an-immersive-experience)

Create an immersive experience by making your app’s content respond to the local shape of the world.

[

Locating and decoding barcodes in 3D space](/documentation/visionOS/locating-and-decoding-barcodes-in-3d-space)

Create engaging, hands-free experiences based on barcodes in a person’s surroundings.

[

Object tracking with Reality Composer Pro experiences](/documentation/visionOS/object-tracking-with-reality-composer-pro-experiences)

Use object tracking in visionOS to attach digital content to real objects to create engaging experiences.

[

Obscuring virtual items in a scene behind real-world items](/documentation/visionOS/obscuring-virtual-items-in-a-scene-behind-real-world-items)

Increase the realism of an immersive experience by adding entities with invisible materials real-world objects.

[

Placing content on detected planes](/documentation/visionOS/placing-content-on-detected-planes)

Detect horizontal surfaces like tables and floors, as well as vertical planes like walls and doors.

[

Placing entities using head and device transform](/documentation/visionOS/placing-entities-using-head-and-device-transform)

Query and react to changes in the position and rotation of Apple Vision Pro.

[

Playing spatial audio](/documentation/visionOS/playing-spatial-audio-in-visionos)

Create and adjust spatial audio in visionOS with RealityKit.

[

Swift Splash](/documentation/visionOS/swift-splash)

Use RealityKit to create an interactive ride in visionOS.

[

Tracking and visualizing hand movement](/documentation/visionOS/tracking-and-visualizing-hand-movement)

Use hand-tracking anchors to display a visual representation of hand transforms in visionOS.

[

Tracking specific points in world space](/documentation/visionOS/tracking-points-in-world-space)

Retrieve the position and orientation of anchors your app stores in ARKit.

### [Watch](/documentation/samplecode/#Watch)

[

Building a productivity app for Apple Watch](/documentation/watchos-apps/building_a_productivity_app_for_apple_watch)

Create a watch app to manage and share a task list and visualize the status with a chart.

[

Create accessible experiences for watchOS](/documentation/watchos-apps/create_accessible_experiences_for_watchos)

Learn how to make your watchOS app more accessible.

[

Creating and updating a complication’s timeline](/documentation/ClockKit/creating-and-updating-a-complication-s-timeline)

Create complications that batch-load a timeline of future entries and run periodic background sessions to update the timeline.

[

Customizing workouts with WorkoutKit](/documentation/WorkoutKit/customizing-workouts-with-workoutkit)

Create, preview, and sync workouts for use in the Workout app on Apple Watch.

[

Developing a User Interface with SwiftUI](/documentation/watchos-apps/developing_a_user_interface_with_swiftui)

Use common SwiftUI elements and watch-specific features in a comprehensive sample app.

[

Displaying essential information on a watch face](/documentation/ClockKit/displaying-essential-information-on-a-watch-face)

Implement complications in a watch app to display essential information on a watch face.

[

Interacting with Bluetooth peripherals during background app refresh](/documentation/WatchKit/interacting-with-bluetooth-peripherals-during-background-app-refresh)

Keep your complications up-to-date by reading values from a Bluetooth peripheral while your app is running in the background.

[

Providing Multiple Complications](/documentation/ClockKit/providing-multiple-complications)

Present multiple complications for a single complication family using descriptors.

[

Transferring data with Watch Connectivity](/documentation/WatchConnectivity/transferring-data-with-watch-connectivity)

Transfer data between a watchOS app and its companion iOS app.

[

Updating your app and widgets for watchOS 10](/documentation/watchOS-Apps/updating-your-app-and-widgets-for-watchos-10)

Integrate SwiftUI elements and watch-specific features, and build widgets for the Smart Stack.

### [Web](/documentation/samplecode/#Web)

[

Adding Context Menus in Your App](/documentation/uikit/uicontrol/adding_context_menus_in_your_app)

Provide quick access to useful actions by adding context menus to your iOS app.

[

Adopting Declarative Content Blocking in Safari Web Extensions](/documentation/SafariServices/adopting-declarative-content-blocking-in-safari-web-extensions)

Block web content with your web extension using the declarative net request API.

[

Adopting New Safari Web Extension APIs](/documentation/SafariServices/adopting-new-safari-web-extension-apis)

Improve your web extension in Safari with a non-persistent background page and new tab-override customization.

[

Creating Safari Web Inspector extensions](/documentation/SafariServices/creating-safari-web-inspector-extensions)

Learn how to make custom Safari Web Inspector extensions.

[

Developing a browser app that uses an alternative browser engine](/documentation/BrowserEngineKit/developing-a-browser-app-that-uses-an-alternative-browser-engine)

Create a web browser app and associated extensions.

[

Developing a Safari Web Extension](/documentation/SafariServices/developing-a-safari-web-extension)

Customize and enhance web pages by building a Safari web extension.

[

Messaging a Web Extension’s Native App](/documentation/SafariServices/messaging-a-web-extension-s-native-app)

Communicate between your Safari web extension and its containing app.

[

Modernizing Safari Web Extensions](/documentation/SafariServices/modernizing-safari-web-extensions)

Learn about enhancements to Safari Web Extensions.

[

Previewing Metadata using Open Graph](/documentation/SafariServices/previewing-metadata-using-open-graph)

Build a Safari Extension that displays metadata using Open Graph.

[

Viewing Desktop or Mobile Web Content Using a Web View](/documentation/WebKit/viewing-desktop-or-mobile-web-content-using-a-web-view)

Implement a simple iPad web browser that can view either the desktop or mobile version of a website.

*   [Sample Code Library](/documentation/samplecode/#app-top)
*   [Featured at WWDC25](/documentation/samplecode/#Featured-at-WWDC25)
*   [Topics](/documentation/samplecode/#topics)